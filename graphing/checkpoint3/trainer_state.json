{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 870,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005747126436781609,
      "grad_norm": 1.209892988204956,
      "learning_rate": 1.8518518518518519e-06,
      "loss": 1.9385,
      "step": 1
    },
    {
      "epoch": 0.011494252873563218,
      "grad_norm": 0.7247292995452881,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 1.8451,
      "step": 2
    },
    {
      "epoch": 0.017241379310344827,
      "grad_norm": 0.5700675845146179,
      "learning_rate": 5.555555555555556e-06,
      "loss": 1.8738,
      "step": 3
    },
    {
      "epoch": 0.022988505747126436,
      "grad_norm": 0.6583515405654907,
      "learning_rate": 7.4074074074074075e-06,
      "loss": 1.8141,
      "step": 4
    },
    {
      "epoch": 0.028735632183908046,
      "grad_norm": 0.7335304617881775,
      "learning_rate": 9.259259259259259e-06,
      "loss": 1.947,
      "step": 5
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 0.7070032358169556,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 2.1848,
      "step": 6
    },
    {
      "epoch": 0.040229885057471264,
      "grad_norm": 0.6534008383750916,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 1.813,
      "step": 7
    },
    {
      "epoch": 0.04597701149425287,
      "grad_norm": 0.6470668315887451,
      "learning_rate": 1.4814814814814815e-05,
      "loss": 2.232,
      "step": 8
    },
    {
      "epoch": 0.05172413793103448,
      "grad_norm": 0.6007290482521057,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.8055,
      "step": 9
    },
    {
      "epoch": 0.05747126436781609,
      "grad_norm": 0.6995158791542053,
      "learning_rate": 1.8518518518518518e-05,
      "loss": 1.7261,
      "step": 10
    },
    {
      "epoch": 0.06321839080459771,
      "grad_norm": 0.6763616800308228,
      "learning_rate": 2.037037037037037e-05,
      "loss": 1.7114,
      "step": 11
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.5809809565544128,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 1.8716,
      "step": 12
    },
    {
      "epoch": 0.07471264367816093,
      "grad_norm": 0.7671087384223938,
      "learning_rate": 2.4074074074074074e-05,
      "loss": 1.714,
      "step": 13
    },
    {
      "epoch": 0.08045977011494253,
      "grad_norm": 0.6630706787109375,
      "learning_rate": 2.5925925925925925e-05,
      "loss": 1.7285,
      "step": 14
    },
    {
      "epoch": 0.08620689655172414,
      "grad_norm": 0.7607190012931824,
      "learning_rate": 2.777777777777778e-05,
      "loss": 1.806,
      "step": 15
    },
    {
      "epoch": 0.09195402298850575,
      "grad_norm": 0.8797848224639893,
      "learning_rate": 2.962962962962963e-05,
      "loss": 1.7827,
      "step": 16
    },
    {
      "epoch": 0.09770114942528736,
      "grad_norm": 0.9733906984329224,
      "learning_rate": 3.148148148148148e-05,
      "loss": 1.7731,
      "step": 17
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 1.072401523590088,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.1886,
      "step": 18
    },
    {
      "epoch": 0.10919540229885058,
      "grad_norm": 0.7823848128318787,
      "learning_rate": 3.518518518518519e-05,
      "loss": 1.7416,
      "step": 19
    },
    {
      "epoch": 0.11494252873563218,
      "grad_norm": 0.9409023523330688,
      "learning_rate": 3.7037037037037037e-05,
      "loss": 1.6298,
      "step": 20
    },
    {
      "epoch": 0.1206896551724138,
      "grad_norm": 0.8133050203323364,
      "learning_rate": 3.888888888888889e-05,
      "loss": 1.7508,
      "step": 21
    },
    {
      "epoch": 0.12643678160919541,
      "grad_norm": 0.9658757448196411,
      "learning_rate": 4.074074074074074e-05,
      "loss": 1.6068,
      "step": 22
    },
    {
      "epoch": 0.13218390804597702,
      "grad_norm": 1.1289551258087158,
      "learning_rate": 4.259259259259259e-05,
      "loss": 1.6039,
      "step": 23
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.9541041851043701,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 1.6187,
      "step": 24
    },
    {
      "epoch": 0.14367816091954022,
      "grad_norm": 1.241036295890808,
      "learning_rate": 4.62962962962963e-05,
      "loss": 1.4338,
      "step": 25
    },
    {
      "epoch": 0.14942528735632185,
      "grad_norm": 1.1581847667694092,
      "learning_rate": 4.814814814814815e-05,
      "loss": 1.3562,
      "step": 26
    },
    {
      "epoch": 0.15517241379310345,
      "grad_norm": 1.2772929668426514,
      "learning_rate": 5e-05,
      "loss": 1.2891,
      "step": 27
    },
    {
      "epoch": 0.16091954022988506,
      "grad_norm": 1.2886476516723633,
      "learning_rate": 4.999982639824691e-05,
      "loss": 1.2934,
      "step": 28
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.9764823913574219,
      "learning_rate": 4.999930559539865e-05,
      "loss": 1.2723,
      "step": 29
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 1.4104385375976562,
      "learning_rate": 4.999843759868819e-05,
      "loss": 1.5535,
      "step": 30
    },
    {
      "epoch": 0.1781609195402299,
      "grad_norm": 0.8110489249229431,
      "learning_rate": 4.99972224201704e-05,
      "loss": 0.9469,
      "step": 31
    },
    {
      "epoch": 0.1839080459770115,
      "grad_norm": 0.811099112033844,
      "learning_rate": 4.999566007672185e-05,
      "loss": 0.9112,
      "step": 32
    },
    {
      "epoch": 0.1896551724137931,
      "grad_norm": 0.8632776737213135,
      "learning_rate": 4.9993750590040575e-05,
      "loss": 0.7619,
      "step": 33
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.1476486921310425,
      "learning_rate": 4.9991493986645815e-05,
      "loss": 0.8382,
      "step": 34
    },
    {
      "epoch": 0.20114942528735633,
      "grad_norm": 1.2224358320236206,
      "learning_rate": 4.998889029787758e-05,
      "loss": 1.3469,
      "step": 35
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.7980790734291077,
      "learning_rate": 4.998593955989626e-05,
      "loss": 0.6471,
      "step": 36
    },
    {
      "epoch": 0.21264367816091953,
      "grad_norm": 0.7674861550331116,
      "learning_rate": 4.998264181368212e-05,
      "loss": 0.5864,
      "step": 37
    },
    {
      "epoch": 0.21839080459770116,
      "grad_norm": 0.7806643843650818,
      "learning_rate": 4.997899710503473e-05,
      "loss": 0.5371,
      "step": 38
    },
    {
      "epoch": 0.22413793103448276,
      "grad_norm": 0.9735392928123474,
      "learning_rate": 4.9975005484572305e-05,
      "loss": 0.72,
      "step": 39
    },
    {
      "epoch": 0.22988505747126436,
      "grad_norm": 0.8462052345275879,
      "learning_rate": 4.997066700773104e-05,
      "loss": 0.4706,
      "step": 40
    },
    {
      "epoch": 0.23563218390804597,
      "grad_norm": 1.0494060516357422,
      "learning_rate": 4.996598173476431e-05,
      "loss": 0.4823,
      "step": 41
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.7021334767341614,
      "learning_rate": 4.996094973074183e-05,
      "loss": 0.3355,
      "step": 42
    },
    {
      "epoch": 0.2471264367816092,
      "grad_norm": 0.8528721332550049,
      "learning_rate": 4.995557106554879e-05,
      "loss": 0.2966,
      "step": 43
    },
    {
      "epoch": 0.25287356321839083,
      "grad_norm": 0.8840854167938232,
      "learning_rate": 4.9949845813884845e-05,
      "loss": 0.2615,
      "step": 44
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 0.6990354061126709,
      "learning_rate": 4.994377405526308e-05,
      "loss": 0.2458,
      "step": 45
    },
    {
      "epoch": 0.26436781609195403,
      "grad_norm": 1.1086927652359009,
      "learning_rate": 4.993735587400895e-05,
      "loss": 0.5642,
      "step": 46
    },
    {
      "epoch": 0.27011494252873564,
      "grad_norm": 1.1422444581985474,
      "learning_rate": 4.9930591359259045e-05,
      "loss": 0.2086,
      "step": 47
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 1.2122349739074707,
      "learning_rate": 4.992348060495989e-05,
      "loss": 0.5148,
      "step": 48
    },
    {
      "epoch": 0.28160919540229884,
      "grad_norm": 0.8306316137313843,
      "learning_rate": 4.991602370986665e-05,
      "loss": 0.1338,
      "step": 49
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 1.3274414539337158,
      "learning_rate": 4.990822077754173e-05,
      "loss": 0.3776,
      "step": 50
    },
    {
      "epoch": 0.29310344827586204,
      "grad_norm": 1.0069416761398315,
      "learning_rate": 4.990007191635334e-05,
      "loss": 0.3685,
      "step": 51
    },
    {
      "epoch": 0.2988505747126437,
      "grad_norm": 0.6876530051231384,
      "learning_rate": 4.989157723947401e-05,
      "loss": 0.1187,
      "step": 52
    },
    {
      "epoch": 0.3045977011494253,
      "grad_norm": 0.36415109038352966,
      "learning_rate": 4.9882736864879e-05,
      "loss": 0.0814,
      "step": 53
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 0.567435622215271,
      "learning_rate": 4.987355091534468e-05,
      "loss": 0.0656,
      "step": 54
    },
    {
      "epoch": 0.3160919540229885,
      "grad_norm": 0.7340360879898071,
      "learning_rate": 4.986401951844679e-05,
      "loss": 0.08,
      "step": 55
    },
    {
      "epoch": 0.3218390804597701,
      "grad_norm": 0.5955982804298401,
      "learning_rate": 4.9854142806558734e-05,
      "loss": 0.0613,
      "step": 56
    },
    {
      "epoch": 0.3275862068965517,
      "grad_norm": 2.031094551086426,
      "learning_rate": 4.9843920916849645e-05,
      "loss": 0.4582,
      "step": 57
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.45910343527793884,
      "learning_rate": 4.983335399128258e-05,
      "loss": 0.0383,
      "step": 58
    },
    {
      "epoch": 0.3390804597701149,
      "grad_norm": 0.4547103941440582,
      "learning_rate": 4.982244217661247e-05,
      "loss": 0.034,
      "step": 59
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.9659498333930969,
      "learning_rate": 4.981118562438414e-05,
      "loss": 0.1698,
      "step": 60
    },
    {
      "epoch": 0.3505747126436782,
      "grad_norm": 0.4082454442977905,
      "learning_rate": 4.979958449093015e-05,
      "loss": 0.0793,
      "step": 61
    },
    {
      "epoch": 0.3563218390804598,
      "grad_norm": 0.5693135261535645,
      "learning_rate": 4.9787638937368674e-05,
      "loss": 0.0606,
      "step": 62
    },
    {
      "epoch": 0.3620689655172414,
      "grad_norm": 0.4276098906993866,
      "learning_rate": 4.9775349129601243e-05,
      "loss": 0.0511,
      "step": 63
    },
    {
      "epoch": 0.367816091954023,
      "grad_norm": 1.0098066329956055,
      "learning_rate": 4.9762715238310434e-05,
      "loss": 0.0785,
      "step": 64
    },
    {
      "epoch": 0.3735632183908046,
      "grad_norm": 0.6329657435417175,
      "learning_rate": 4.974973743895749e-05,
      "loss": 0.0862,
      "step": 65
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 0.8417543768882751,
      "learning_rate": 4.973641591177991e-05,
      "loss": 0.0846,
      "step": 66
    },
    {
      "epoch": 0.3850574712643678,
      "grad_norm": 0.956015944480896,
      "learning_rate": 4.972275084178893e-05,
      "loss": 0.0848,
      "step": 67
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 3.0775973796844482,
      "learning_rate": 4.9708742418766966e-05,
      "loss": 0.1666,
      "step": 68
    },
    {
      "epoch": 0.39655172413793105,
      "grad_norm": 0.34280234575271606,
      "learning_rate": 4.969439083726496e-05,
      "loss": 0.0451,
      "step": 69
    },
    {
      "epoch": 0.40229885057471265,
      "grad_norm": 0.47098225355148315,
      "learning_rate": 4.9679696296599686e-05,
      "loss": 0.0343,
      "step": 70
    },
    {
      "epoch": 0.40804597701149425,
      "grad_norm": 0.5544074177742004,
      "learning_rate": 4.9664659000850984e-05,
      "loss": 0.0449,
      "step": 71
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.8501888513565063,
      "learning_rate": 4.964927915885893e-05,
      "loss": 0.0743,
      "step": 72
    },
    {
      "epoch": 0.41954022988505746,
      "grad_norm": 0.1985323131084442,
      "learning_rate": 4.963355698422092e-05,
      "loss": 0.0132,
      "step": 73
    },
    {
      "epoch": 0.42528735632183906,
      "grad_norm": 1.4743216037750244,
      "learning_rate": 4.961749269528873e-05,
      "loss": 0.2544,
      "step": 74
    },
    {
      "epoch": 0.43103448275862066,
      "grad_norm": 0.5733113288879395,
      "learning_rate": 4.960108651516545e-05,
      "loss": 0.0487,
      "step": 75
    },
    {
      "epoch": 0.4367816091954023,
      "grad_norm": 0.3191516697406769,
      "learning_rate": 4.9584338671702416e-05,
      "loss": 0.0303,
      "step": 76
    },
    {
      "epoch": 0.4425287356321839,
      "grad_norm": 0.5883174538612366,
      "learning_rate": 4.9567249397496024e-05,
      "loss": 0.0446,
      "step": 77
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 0.7004194855690002,
      "learning_rate": 4.954981892988451e-05,
      "loss": 0.067,
      "step": 78
    },
    {
      "epoch": 0.4540229885057471,
      "grad_norm": 0.5320835113525391,
      "learning_rate": 4.9532047510944654e-05,
      "loss": 0.0538,
      "step": 79
    },
    {
      "epoch": 0.45977011494252873,
      "grad_norm": 0.3482046127319336,
      "learning_rate": 4.951393538748842e-05,
      "loss": 0.0223,
      "step": 80
    },
    {
      "epoch": 0.46551724137931033,
      "grad_norm": 0.42307043075561523,
      "learning_rate": 4.949548281105951e-05,
      "loss": 0.0263,
      "step": 81
    },
    {
      "epoch": 0.47126436781609193,
      "grad_norm": 0.6732980608940125,
      "learning_rate": 4.94766900379299e-05,
      "loss": 0.0655,
      "step": 82
    },
    {
      "epoch": 0.47701149425287354,
      "grad_norm": 0.6243898272514343,
      "learning_rate": 4.945755732909625e-05,
      "loss": 0.0616,
      "step": 83
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 1.156335473060608,
      "learning_rate": 4.943808495027631e-05,
      "loss": 0.2051,
      "step": 84
    },
    {
      "epoch": 0.4885057471264368,
      "grad_norm": 1.0167535543441772,
      "learning_rate": 4.941827317190521e-05,
      "loss": 0.1985,
      "step": 85
    },
    {
      "epoch": 0.4942528735632184,
      "grad_norm": 0.9262468218803406,
      "learning_rate": 4.93981222691317e-05,
      "loss": 0.1323,
      "step": 86
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6467636227607727,
      "learning_rate": 4.937763252181434e-05,
      "loss": 0.0553,
      "step": 87
    },
    {
      "epoch": 0.5057471264367817,
      "grad_norm": 0.6183954477310181,
      "learning_rate": 4.935680421451764e-05,
      "loss": 0.1206,
      "step": 88
    },
    {
      "epoch": 0.5114942528735632,
      "grad_norm": 0.590704083442688,
      "learning_rate": 4.933563763650803e-05,
      "loss": 0.0491,
      "step": 89
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.29078400135040283,
      "learning_rate": 4.93141330817499e-05,
      "loss": 0.0258,
      "step": 90
    },
    {
      "epoch": 0.5229885057471264,
      "grad_norm": 0.7009259462356567,
      "learning_rate": 4.9292290848901565e-05,
      "loss": 0.0416,
      "step": 91
    },
    {
      "epoch": 0.5287356321839081,
      "grad_norm": 0.3310457766056061,
      "learning_rate": 4.927011124131098e-05,
      "loss": 0.0334,
      "step": 92
    },
    {
      "epoch": 0.5344827586206896,
      "grad_norm": 0.6449072360992432,
      "learning_rate": 4.924759456701167e-05,
      "loss": 0.0506,
      "step": 93
    },
    {
      "epoch": 0.5402298850574713,
      "grad_norm": 0.3698577880859375,
      "learning_rate": 4.9224741138718344e-05,
      "loss": 0.0284,
      "step": 94
    },
    {
      "epoch": 0.5459770114942529,
      "grad_norm": 0.2967434823513031,
      "learning_rate": 4.9201551273822644e-05,
      "loss": 0.0314,
      "step": 95
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.9165907502174377,
      "learning_rate": 4.917802529438864e-05,
      "loss": 0.0897,
      "step": 96
    },
    {
      "epoch": 0.5574712643678161,
      "grad_norm": 0.3614521026611328,
      "learning_rate": 4.915416352714846e-05,
      "loss": 0.0443,
      "step": 97
    },
    {
      "epoch": 0.5632183908045977,
      "grad_norm": 1.4987411499023438,
      "learning_rate": 4.912996630349766e-05,
      "loss": 0.0853,
      "step": 98
    },
    {
      "epoch": 0.5689655172413793,
      "grad_norm": 1.3016636371612549,
      "learning_rate": 4.910543395949067e-05,
      "loss": 0.106,
      "step": 99
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 0.391369104385376,
      "learning_rate": 4.9080566835836126e-05,
      "loss": 0.0364,
      "step": 100
    },
    {
      "epoch": 0.5804597701149425,
      "grad_norm": 0.33197733759880066,
      "learning_rate": 4.905536527789214e-05,
      "loss": 0.043,
      "step": 101
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.5994808673858643,
      "learning_rate": 4.9029829635661475e-05,
      "loss": 0.039,
      "step": 102
    },
    {
      "epoch": 0.5919540229885057,
      "grad_norm": 0.6465499997138977,
      "learning_rate": 4.9003960263786705e-05,
      "loss": 0.0419,
      "step": 103
    },
    {
      "epoch": 0.5977011494252874,
      "grad_norm": 0.7009406089782715,
      "learning_rate": 4.897775752154532e-05,
      "loss": 0.0538,
      "step": 104
    },
    {
      "epoch": 0.603448275862069,
      "grad_norm": 0.47987571358680725,
      "learning_rate": 4.895122177284465e-05,
      "loss": 0.0293,
      "step": 105
    },
    {
      "epoch": 0.6091954022988506,
      "grad_norm": 0.30649030208587646,
      "learning_rate": 4.892435338621692e-05,
      "loss": 0.0222,
      "step": 106
    },
    {
      "epoch": 0.6149425287356322,
      "grad_norm": 0.6136652231216431,
      "learning_rate": 4.889715273481402e-05,
      "loss": 0.0546,
      "step": 107
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.5030955076217651,
      "learning_rate": 4.8869620196402436e-05,
      "loss": 0.0569,
      "step": 108
    },
    {
      "epoch": 0.6264367816091954,
      "grad_norm": 0.6108970046043396,
      "learning_rate": 4.884175615335792e-05,
      "loss": 0.0416,
      "step": 109
    },
    {
      "epoch": 0.632183908045977,
      "grad_norm": 0.34193137288093567,
      "learning_rate": 4.8813560992660205e-05,
      "loss": 0.0464,
      "step": 110
    },
    {
      "epoch": 0.6379310344827587,
      "grad_norm": 0.35021519660949707,
      "learning_rate": 4.878503510588765e-05,
      "loss": 0.0386,
      "step": 111
    },
    {
      "epoch": 0.6436781609195402,
      "grad_norm": 0.28415340185165405,
      "learning_rate": 4.875617888921173e-05,
      "loss": 0.0288,
      "step": 112
    },
    {
      "epoch": 0.6494252873563219,
      "grad_norm": 0.36718735098838806,
      "learning_rate": 4.8726992743391684e-05,
      "loss": 0.026,
      "step": 113
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.3543875217437744,
      "learning_rate": 4.8697477073768766e-05,
      "loss": 0.0283,
      "step": 114
    },
    {
      "epoch": 0.6609195402298851,
      "grad_norm": 0.7759935855865479,
      "learning_rate": 4.8667632290260744e-05,
      "loss": 0.0444,
      "step": 115
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.4167880713939667,
      "learning_rate": 4.863745880735615e-05,
      "loss": 0.0596,
      "step": 116
    },
    {
      "epoch": 0.6724137931034483,
      "grad_norm": 0.428550660610199,
      "learning_rate": 4.8606957044108556e-05,
      "loss": 0.0307,
      "step": 117
    },
    {
      "epoch": 0.6781609195402298,
      "grad_norm": 0.6411188840866089,
      "learning_rate": 4.8576127424130726e-05,
      "loss": 0.042,
      "step": 118
    },
    {
      "epoch": 0.6839080459770115,
      "grad_norm": 0.6421493887901306,
      "learning_rate": 4.8544970375588735e-05,
      "loss": 0.038,
      "step": 119
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.20215827226638794,
      "learning_rate": 4.851348633119606e-05,
      "loss": 0.0116,
      "step": 120
    },
    {
      "epoch": 0.6954022988505747,
      "grad_norm": 0.32951200008392334,
      "learning_rate": 4.848167572820751e-05,
      "loss": 0.0256,
      "step": 121
    },
    {
      "epoch": 0.7011494252873564,
      "grad_norm": 2.6212382316589355,
      "learning_rate": 4.844953900841321e-05,
      "loss": 0.0801,
      "step": 122
    },
    {
      "epoch": 0.7068965517241379,
      "grad_norm": 0.37242621183395386,
      "learning_rate": 4.8417076618132426e-05,
      "loss": 0.0387,
      "step": 123
    },
    {
      "epoch": 0.7126436781609196,
      "grad_norm": 0.7977843880653381,
      "learning_rate": 4.83842890082074e-05,
      "loss": 0.0974,
      "step": 124
    },
    {
      "epoch": 0.7183908045977011,
      "grad_norm": 0.46354103088378906,
      "learning_rate": 4.835117663399703e-05,
      "loss": 0.0193,
      "step": 125
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.4420248568058014,
      "learning_rate": 4.8317739955370636e-05,
      "loss": 0.0668,
      "step": 126
    },
    {
      "epoch": 0.7298850574712644,
      "grad_norm": 0.32163307070732117,
      "learning_rate": 4.82839794367015e-05,
      "loss": 0.0323,
      "step": 127
    },
    {
      "epoch": 0.735632183908046,
      "grad_norm": 0.21165600419044495,
      "learning_rate": 4.824989554686042e-05,
      "loss": 0.02,
      "step": 128
    },
    {
      "epoch": 0.7413793103448276,
      "grad_norm": 0.09462825953960419,
      "learning_rate": 4.821548875920927e-05,
      "loss": 0.016,
      "step": 129
    },
    {
      "epoch": 0.7471264367816092,
      "grad_norm": 0.40167492628097534,
      "learning_rate": 4.818075955159431e-05,
      "loss": 0.0434,
      "step": 130
    },
    {
      "epoch": 0.7528735632183908,
      "grad_norm": 0.3176672160625458,
      "learning_rate": 4.8145708406339666e-05,
      "loss": 0.0399,
      "step": 131
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.19370652735233307,
      "learning_rate": 4.811033581024056e-05,
      "loss": 0.0229,
      "step": 132
    },
    {
      "epoch": 0.764367816091954,
      "grad_norm": 0.37421268224716187,
      "learning_rate": 4.807464225455655e-05,
      "loss": 0.0551,
      "step": 133
    },
    {
      "epoch": 0.7701149425287356,
      "grad_norm": 0.3152390420436859,
      "learning_rate": 4.803862823500476e-05,
      "loss": 0.0203,
      "step": 134
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 0.28489992022514343,
      "learning_rate": 4.800229425175294e-05,
      "loss": 0.052,
      "step": 135
    },
    {
      "epoch": 0.7816091954022989,
      "grad_norm": 0.3136906623840332,
      "learning_rate": 4.796564080941254e-05,
      "loss": 0.0353,
      "step": 136
    },
    {
      "epoch": 0.7873563218390804,
      "grad_norm": 0.5305456519126892,
      "learning_rate": 4.792866841703171e-05,
      "loss": 0.0497,
      "step": 137
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.7712120413780212,
      "learning_rate": 4.7891377588088223e-05,
      "loss": 0.0579,
      "step": 138
    },
    {
      "epoch": 0.7988505747126436,
      "grad_norm": 0.5058746337890625,
      "learning_rate": 4.785376884048235e-05,
      "loss": 0.0781,
      "step": 139
    },
    {
      "epoch": 0.8045977011494253,
      "grad_norm": 0.3436695635318756,
      "learning_rate": 4.781584269652963e-05,
      "loss": 0.0404,
      "step": 140
    },
    {
      "epoch": 0.8103448275862069,
      "grad_norm": 0.40079084038734436,
      "learning_rate": 4.777759968295369e-05,
      "loss": 0.0784,
      "step": 141
    },
    {
      "epoch": 0.8160919540229885,
      "grad_norm": 0.4927098751068115,
      "learning_rate": 4.773904033087886e-05,
      "loss": 0.0596,
      "step": 142
    },
    {
      "epoch": 0.8218390804597702,
      "grad_norm": 0.4222378134727478,
      "learning_rate": 4.770016517582283e-05,
      "loss": 0.0575,
      "step": 143
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.34435945749282837,
      "learning_rate": 4.766097475768919e-05,
      "loss": 0.0502,
      "step": 144
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.23859535157680511,
      "learning_rate": 4.762146962075999e-05,
      "loss": 0.0281,
      "step": 145
    },
    {
      "epoch": 0.8390804597701149,
      "grad_norm": 0.8263512253761292,
      "learning_rate": 4.758165031368809e-05,
      "loss": 0.0505,
      "step": 146
    },
    {
      "epoch": 0.8448275862068966,
      "grad_norm": 0.28550985455513,
      "learning_rate": 4.754151738948962e-05,
      "loss": 0.0292,
      "step": 147
    },
    {
      "epoch": 0.8505747126436781,
      "grad_norm": 0.273943692445755,
      "learning_rate": 4.750107140553627e-05,
      "loss": 0.033,
      "step": 148
    },
    {
      "epoch": 0.8563218390804598,
      "grad_norm": 0.21441026031970978,
      "learning_rate": 4.746031292354752e-05,
      "loss": 0.0313,
      "step": 149
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.3885469138622284,
      "learning_rate": 4.741924250958289e-05,
      "loss": 0.0507,
      "step": 150
    },
    {
      "epoch": 0.867816091954023,
      "grad_norm": 0.32398125529289246,
      "learning_rate": 4.737786073403405e-05,
      "loss": 0.0307,
      "step": 151
    },
    {
      "epoch": 0.8735632183908046,
      "grad_norm": 0.3108004033565521,
      "learning_rate": 4.73361681716169e-05,
      "loss": 0.0332,
      "step": 152
    },
    {
      "epoch": 0.8793103448275862,
      "grad_norm": 1.7460483312606812,
      "learning_rate": 4.729416540136361e-05,
      "loss": 0.0398,
      "step": 153
    },
    {
      "epoch": 0.8850574712643678,
      "grad_norm": 0.17648696899414062,
      "learning_rate": 4.725185300661452e-05,
      "loss": 0.0227,
      "step": 154
    },
    {
      "epoch": 0.8908045977011494,
      "grad_norm": 0.5525690913200378,
      "learning_rate": 4.720923157501012e-05,
      "loss": 0.0582,
      "step": 155
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.21192359924316406,
      "learning_rate": 4.7166301698482815e-05,
      "loss": 0.0185,
      "step": 156
    },
    {
      "epoch": 0.9022988505747126,
      "grad_norm": 0.5594702363014221,
      "learning_rate": 4.712306397324877e-05,
      "loss": 0.0566,
      "step": 157
    },
    {
      "epoch": 0.9080459770114943,
      "grad_norm": 0.4931170344352722,
      "learning_rate": 4.707951899979956e-05,
      "loss": 0.0448,
      "step": 158
    },
    {
      "epoch": 0.9137931034482759,
      "grad_norm": 0.5142996907234192,
      "learning_rate": 4.703566738289389e-05,
      "loss": 0.0437,
      "step": 159
    },
    {
      "epoch": 0.9195402298850575,
      "grad_norm": 0.6245520710945129,
      "learning_rate": 4.699150973154916e-05,
      "loss": 0.0469,
      "step": 160
    },
    {
      "epoch": 0.9252873563218391,
      "grad_norm": 0.1916884332895279,
      "learning_rate": 4.6947046659033045e-05,
      "loss": 0.0144,
      "step": 161
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 0.438754141330719,
      "learning_rate": 4.69022787828549e-05,
      "loss": 0.0249,
      "step": 162
    },
    {
      "epoch": 0.9367816091954023,
      "grad_norm": 0.4019363820552826,
      "learning_rate": 4.6857206724757296e-05,
      "loss": 0.0267,
      "step": 163
    },
    {
      "epoch": 0.9425287356321839,
      "grad_norm": 0.4338836073875427,
      "learning_rate": 4.681183111070729e-05,
      "loss": 0.0255,
      "step": 164
    },
    {
      "epoch": 0.9482758620689655,
      "grad_norm": 1.669561505317688,
      "learning_rate": 4.676615257088776e-05,
      "loss": 0.0777,
      "step": 165
    },
    {
      "epoch": 0.9540229885057471,
      "grad_norm": 0.37403061985969543,
      "learning_rate": 4.6720171739688687e-05,
      "loss": 0.0498,
      "step": 166
    },
    {
      "epoch": 0.9597701149425287,
      "grad_norm": 0.35261818766593933,
      "learning_rate": 4.66738892556983e-05,
      "loss": 0.0484,
      "step": 167
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.21031200885772705,
      "learning_rate": 4.662730576169423e-05,
      "loss": 0.012,
      "step": 168
    },
    {
      "epoch": 0.9712643678160919,
      "grad_norm": 0.3873611092567444,
      "learning_rate": 4.6580421904634565e-05,
      "loss": 0.0292,
      "step": 169
    },
    {
      "epoch": 0.9770114942528736,
      "grad_norm": 0.5329460501670837,
      "learning_rate": 4.65332383356489e-05,
      "loss": 0.0476,
      "step": 170
    },
    {
      "epoch": 0.9827586206896551,
      "grad_norm": 0.2727585732936859,
      "learning_rate": 4.6485755710029256e-05,
      "loss": 0.0294,
      "step": 171
    },
    {
      "epoch": 0.9885057471264368,
      "grad_norm": 0.36710092425346375,
      "learning_rate": 4.6437974687220985e-05,
      "loss": 0.054,
      "step": 172
    },
    {
      "epoch": 0.9942528735632183,
      "grad_norm": 0.31792616844177246,
      "learning_rate": 4.638989593081364e-05,
      "loss": 0.036,
      "step": 173
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.19973917305469513,
      "learning_rate": 4.6341520108531746e-05,
      "loss": 0.0102,
      "step": 174
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.03295924887061119,
      "eval_runtime": 98.2155,
      "eval_samples_per_second": 0.896,
      "eval_steps_per_second": 0.448,
      "step": 174
    },
    {
      "epoch": 1.0057471264367817,
      "grad_norm": 0.16103194653987885,
      "learning_rate": 4.629284789222549e-05,
      "loss": 0.0214,
      "step": 175
    },
    {
      "epoch": 1.0114942528735633,
      "grad_norm": 0.13759995996952057,
      "learning_rate": 4.6243879957861444e-05,
      "loss": 0.0239,
      "step": 176
    },
    {
      "epoch": 1.0172413793103448,
      "grad_norm": 0.29970136284828186,
      "learning_rate": 4.619461698551315e-05,
      "loss": 0.0628,
      "step": 177
    },
    {
      "epoch": 1.0229885057471264,
      "grad_norm": 0.16616666316986084,
      "learning_rate": 4.614505965935167e-05,
      "loss": 0.0204,
      "step": 178
    },
    {
      "epoch": 1.028735632183908,
      "grad_norm": 0.13205936551094055,
      "learning_rate": 4.6095208667636106e-05,
      "loss": 0.0192,
      "step": 179
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.24906979501247406,
      "learning_rate": 4.604506470270403e-05,
      "loss": 0.0203,
      "step": 180
    },
    {
      "epoch": 1.0402298850574712,
      "grad_norm": 0.21761932969093323,
      "learning_rate": 4.599462846096184e-05,
      "loss": 0.0317,
      "step": 181
    },
    {
      "epoch": 1.0459770114942528,
      "grad_norm": 0.2967589199542999,
      "learning_rate": 4.594390064287515e-05,
      "loss": 0.0213,
      "step": 182
    },
    {
      "epoch": 1.0517241379310345,
      "grad_norm": 0.1753671020269394,
      "learning_rate": 4.589288195295901e-05,
      "loss": 0.0187,
      "step": 183
    },
    {
      "epoch": 1.0574712643678161,
      "grad_norm": 0.22199776768684387,
      "learning_rate": 4.584157309976814e-05,
      "loss": 0.0301,
      "step": 184
    },
    {
      "epoch": 1.0632183908045978,
      "grad_norm": 0.29424795508384705,
      "learning_rate": 4.578997479588708e-05,
      "loss": 0.0702,
      "step": 185
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 0.21677765250205994,
      "learning_rate": 4.573808775792033e-05,
      "loss": 0.0315,
      "step": 186
    },
    {
      "epoch": 1.0747126436781609,
      "grad_norm": 0.10691762715578079,
      "learning_rate": 4.568591270648233e-05,
      "loss": 0.0215,
      "step": 187
    },
    {
      "epoch": 1.0804597701149425,
      "grad_norm": 0.28467684984207153,
      "learning_rate": 4.563345036618752e-05,
      "loss": 0.0339,
      "step": 188
    },
    {
      "epoch": 1.0862068965517242,
      "grad_norm": 0.20498859882354736,
      "learning_rate": 4.5580701465640254e-05,
      "loss": 0.0281,
      "step": 189
    },
    {
      "epoch": 1.0919540229885056,
      "grad_norm": 0.2816928029060364,
      "learning_rate": 4.5527666737424636e-05,
      "loss": 0.0248,
      "step": 190
    },
    {
      "epoch": 1.0977011494252873,
      "grad_norm": 0.23676180839538574,
      "learning_rate": 4.5474346918094416e-05,
      "loss": 0.0235,
      "step": 191
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.2036612629890442,
      "learning_rate": 4.5420742748162734e-05,
      "loss": 0.0258,
      "step": 192
    },
    {
      "epoch": 1.1091954022988506,
      "grad_norm": 0.16089406609535217,
      "learning_rate": 4.5366854972091814e-05,
      "loss": 0.0213,
      "step": 193
    },
    {
      "epoch": 1.1149425287356323,
      "grad_norm": 0.09372446686029434,
      "learning_rate": 4.5312684338282645e-05,
      "loss": 0.0191,
      "step": 194
    },
    {
      "epoch": 1.1206896551724137,
      "grad_norm": 0.3093145489692688,
      "learning_rate": 4.525823159906459e-05,
      "loss": 0.0655,
      "step": 195
    },
    {
      "epoch": 1.1264367816091954,
      "grad_norm": 0.1617485135793686,
      "learning_rate": 4.5203497510684926e-05,
      "loss": 0.0234,
      "step": 196
    },
    {
      "epoch": 1.132183908045977,
      "grad_norm": 0.18062639236450195,
      "learning_rate": 4.514848283329835e-05,
      "loss": 0.013,
      "step": 197
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 0.23945817351341248,
      "learning_rate": 4.509318833095642e-05,
      "loss": 0.0244,
      "step": 198
    },
    {
      "epoch": 1.1436781609195403,
      "grad_norm": 0.1896999180316925,
      "learning_rate": 4.503761477159693e-05,
      "loss": 0.0265,
      "step": 199
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 0.4471984803676605,
      "learning_rate": 4.4981762927033264e-05,
      "loss": 0.0267,
      "step": 200
    },
    {
      "epoch": 1.1551724137931034,
      "grad_norm": 0.21484553813934326,
      "learning_rate": 4.492563357294369e-05,
      "loss": 0.0229,
      "step": 201
    },
    {
      "epoch": 1.160919540229885,
      "grad_norm": 0.10555263608694077,
      "learning_rate": 4.486922748886054e-05,
      "loss": 0.0147,
      "step": 202
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.12830621004104614,
      "learning_rate": 4.4812545458159425e-05,
      "loss": 0.0183,
      "step": 203
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.1412753462791443,
      "learning_rate": 4.475558826804833e-05,
      "loss": 0.01,
      "step": 204
    },
    {
      "epoch": 1.1781609195402298,
      "grad_norm": 0.11034359782934189,
      "learning_rate": 4.4698356709556707e-05,
      "loss": 0.0158,
      "step": 205
    },
    {
      "epoch": 1.1839080459770115,
      "grad_norm": 0.2911583483219147,
      "learning_rate": 4.464085157752446e-05,
      "loss": 0.0157,
      "step": 206
    },
    {
      "epoch": 1.1896551724137931,
      "grad_norm": 0.3354097902774811,
      "learning_rate": 4.458307367059092e-05,
      "loss": 0.0387,
      "step": 207
    },
    {
      "epoch": 1.1954022988505748,
      "grad_norm": 0.1625829041004181,
      "learning_rate": 4.452502379118377e-05,
      "loss": 0.0103,
      "step": 208
    },
    {
      "epoch": 1.2011494252873562,
      "grad_norm": 0.3371879458427429,
      "learning_rate": 4.4466702745507894e-05,
      "loss": 0.015,
      "step": 209
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.2334984987974167,
      "learning_rate": 4.440811134353412e-05,
      "loss": 0.0272,
      "step": 210
    },
    {
      "epoch": 1.2126436781609196,
      "grad_norm": 0.4044075906276703,
      "learning_rate": 4.434925039898809e-05,
      "loss": 0.0211,
      "step": 211
    },
    {
      "epoch": 1.2183908045977012,
      "grad_norm": 0.3112414479255676,
      "learning_rate": 4.429012072933884e-05,
      "loss": 0.0382,
      "step": 212
    },
    {
      "epoch": 1.2241379310344827,
      "grad_norm": 0.2662665843963623,
      "learning_rate": 4.42307231557875e-05,
      "loss": 0.0111,
      "step": 213
    },
    {
      "epoch": 1.2298850574712643,
      "grad_norm": 0.2765445113182068,
      "learning_rate": 4.4171058503255925e-05,
      "loss": 0.0133,
      "step": 214
    },
    {
      "epoch": 1.235632183908046,
      "grad_norm": 0.29510772228240967,
      "learning_rate": 4.411112760037517e-05,
      "loss": 0.0142,
      "step": 215
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.2416292279958725,
      "learning_rate": 4.4050931279474015e-05,
      "loss": 0.0133,
      "step": 216
    },
    {
      "epoch": 1.2471264367816093,
      "grad_norm": 0.1452159881591797,
      "learning_rate": 4.399047037656741e-05,
      "loss": 0.0185,
      "step": 217
    },
    {
      "epoch": 1.2528735632183907,
      "grad_norm": 0.4287063777446747,
      "learning_rate": 4.392974573134486e-05,
      "loss": 0.0435,
      "step": 218
    },
    {
      "epoch": 1.2586206896551724,
      "grad_norm": 0.11359460651874542,
      "learning_rate": 4.386875818715874e-05,
      "loss": 0.007,
      "step": 219
    },
    {
      "epoch": 1.264367816091954,
      "grad_norm": 0.6837815642356873,
      "learning_rate": 4.380750859101264e-05,
      "loss": 0.0991,
      "step": 220
    },
    {
      "epoch": 1.2701149425287357,
      "grad_norm": 0.11547869443893433,
      "learning_rate": 4.374599779354952e-05,
      "loss": 0.0097,
      "step": 221
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 0.09994424134492874,
      "learning_rate": 4.368422664903997e-05,
      "loss": 0.0064,
      "step": 222
    },
    {
      "epoch": 1.2816091954022988,
      "grad_norm": 0.23136620223522186,
      "learning_rate": 4.362219601537031e-05,
      "loss": 0.0214,
      "step": 223
    },
    {
      "epoch": 1.2873563218390804,
      "grad_norm": 0.45493319630622864,
      "learning_rate": 4.355990675403067e-05,
      "loss": 0.0401,
      "step": 224
    },
    {
      "epoch": 1.293103448275862,
      "grad_norm": 0.11071746796369553,
      "learning_rate": 4.349735973010305e-05,
      "loss": 0.0164,
      "step": 225
    },
    {
      "epoch": 1.2988505747126438,
      "grad_norm": 0.2785896062850952,
      "learning_rate": 4.343455581224931e-05,
      "loss": 0.0278,
      "step": 226
    },
    {
      "epoch": 1.3045977011494254,
      "grad_norm": 0.3166150152683258,
      "learning_rate": 4.3371495872699044e-05,
      "loss": 0.0162,
      "step": 227
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.5247818231582642,
      "learning_rate": 4.330818078723755e-05,
      "loss": 0.0319,
      "step": 228
    },
    {
      "epoch": 1.3160919540229885,
      "grad_norm": 0.18891429901123047,
      "learning_rate": 4.3244611435193615e-05,
      "loss": 0.0161,
      "step": 229
    },
    {
      "epoch": 1.3218390804597702,
      "grad_norm": 0.4635711908340454,
      "learning_rate": 4.318078869942731e-05,
      "loss": 0.0258,
      "step": 230
    },
    {
      "epoch": 1.3275862068965516,
      "grad_norm": 0.20361728966236115,
      "learning_rate": 4.311671346631774e-05,
      "loss": 0.0154,
      "step": 231
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.3828836977481842,
      "learning_rate": 4.3052386625750736e-05,
      "loss": 0.0273,
      "step": 232
    },
    {
      "epoch": 1.339080459770115,
      "grad_norm": 0.5689548254013062,
      "learning_rate": 4.298780907110647e-05,
      "loss": 0.075,
      "step": 233
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.24404412508010864,
      "learning_rate": 4.292298169924709e-05,
      "loss": 0.0157,
      "step": 234
    },
    {
      "epoch": 1.3505747126436782,
      "grad_norm": 0.2037382423877716,
      "learning_rate": 4.285790541050422e-05,
      "loss": 0.0166,
      "step": 235
    },
    {
      "epoch": 1.3563218390804597,
      "grad_norm": 0.48663297295570374,
      "learning_rate": 4.279258110866648e-05,
      "loss": 0.0262,
      "step": 236
    },
    {
      "epoch": 1.3620689655172413,
      "grad_norm": 0.4431343674659729,
      "learning_rate": 4.272700970096696e-05,
      "loss": 0.0277,
      "step": 237
    },
    {
      "epoch": 1.367816091954023,
      "grad_norm": 0.17442259192466736,
      "learning_rate": 4.2661192098070534e-05,
      "loss": 0.0128,
      "step": 238
    },
    {
      "epoch": 1.3735632183908046,
      "grad_norm": 0.2865220606327057,
      "learning_rate": 4.259512921406133e-05,
      "loss": 0.0453,
      "step": 239
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.265412837266922,
      "learning_rate": 4.252882196642992e-05,
      "loss": 0.0187,
      "step": 240
    },
    {
      "epoch": 1.3850574712643677,
      "grad_norm": 0.23749063909053802,
      "learning_rate": 4.246227127606068e-05,
      "loss": 0.0306,
      "step": 241
    },
    {
      "epoch": 1.3908045977011494,
      "grad_norm": 0.39415523409843445,
      "learning_rate": 4.239547806721892e-05,
      "loss": 0.0565,
      "step": 242
    },
    {
      "epoch": 1.396551724137931,
      "grad_norm": 0.21863286197185516,
      "learning_rate": 4.23284432675381e-05,
      "loss": 0.0246,
      "step": 243
    },
    {
      "epoch": 1.4022988505747127,
      "grad_norm": 0.1336023062467575,
      "learning_rate": 4.2261167808006905e-05,
      "loss": 0.0086,
      "step": 244
    },
    {
      "epoch": 1.4080459770114944,
      "grad_norm": 0.5125362873077393,
      "learning_rate": 4.219365262295637e-05,
      "loss": 0.0349,
      "step": 245
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 1.0571224689483643,
      "learning_rate": 4.212589865004684e-05,
      "loss": 0.1391,
      "step": 246
    },
    {
      "epoch": 1.4195402298850575,
      "grad_norm": 0.21931414306163788,
      "learning_rate": 4.2057906830255e-05,
      "loss": 0.0197,
      "step": 247
    },
    {
      "epoch": 1.4252873563218391,
      "grad_norm": 0.20417720079421997,
      "learning_rate": 4.198967810786078e-05,
      "loss": 0.014,
      "step": 248
    },
    {
      "epoch": 1.4310344827586206,
      "grad_norm": 0.8551746606826782,
      "learning_rate": 4.192121343043424e-05,
      "loss": 0.0973,
      "step": 249
    },
    {
      "epoch": 1.4367816091954024,
      "grad_norm": 0.24648375809192657,
      "learning_rate": 4.185251374882243e-05,
      "loss": 0.04,
      "step": 250
    },
    {
      "epoch": 1.4425287356321839,
      "grad_norm": 0.2524779140949249,
      "learning_rate": 4.178358001713615e-05,
      "loss": 0.0186,
      "step": 251
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.42071425914764404,
      "learning_rate": 4.1714413192736754e-05,
      "loss": 0.0241,
      "step": 252
    },
    {
      "epoch": 1.4540229885057472,
      "grad_norm": 0.22482115030288696,
      "learning_rate": 4.1645014236222775e-05,
      "loss": 0.0209,
      "step": 253
    },
    {
      "epoch": 1.4597701149425286,
      "grad_norm": 0.2914706766605377,
      "learning_rate": 4.157538411141667e-05,
      "loss": 0.0275,
      "step": 254
    },
    {
      "epoch": 1.4655172413793103,
      "grad_norm": 0.19642414152622223,
      "learning_rate": 4.150552378535137e-05,
      "loss": 0.0264,
      "step": 255
    },
    {
      "epoch": 1.471264367816092,
      "grad_norm": 0.28763458132743835,
      "learning_rate": 4.14354342282569e-05,
      "loss": 0.034,
      "step": 256
    },
    {
      "epoch": 1.4770114942528736,
      "grad_norm": 0.4206834137439728,
      "learning_rate": 4.136511641354683e-05,
      "loss": 0.0356,
      "step": 257
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 0.36994612216949463,
      "learning_rate": 4.1294571317804854e-05,
      "loss": 0.0195,
      "step": 258
    },
    {
      "epoch": 1.4885057471264367,
      "grad_norm": 0.44026023149490356,
      "learning_rate": 4.1223799920771144e-05,
      "loss": 0.0253,
      "step": 259
    },
    {
      "epoch": 1.4942528735632183,
      "grad_norm": 0.22778040170669556,
      "learning_rate": 4.1152803205328794e-05,
      "loss": 0.02,
      "step": 260
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19337323307991028,
      "learning_rate": 4.108158215749014e-05,
      "loss": 0.0199,
      "step": 261
    },
    {
      "epoch": 1.5057471264367817,
      "grad_norm": 0.31317976117134094,
      "learning_rate": 4.101013776638309e-05,
      "loss": 0.0302,
      "step": 262
    },
    {
      "epoch": 1.5114942528735633,
      "grad_norm": 0.13086366653442383,
      "learning_rate": 4.0938471024237355e-05,
      "loss": 0.0129,
      "step": 263
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.21555066108703613,
      "learning_rate": 4.0866582926370725e-05,
      "loss": 0.0285,
      "step": 264
    },
    {
      "epoch": 1.5229885057471264,
      "grad_norm": 0.20703595876693726,
      "learning_rate": 4.0794474471175154e-05,
      "loss": 0.0277,
      "step": 265
    },
    {
      "epoch": 1.528735632183908,
      "grad_norm": 0.2329465001821518,
      "learning_rate": 4.0722146660103e-05,
      "loss": 0.0268,
      "step": 266
    },
    {
      "epoch": 1.5344827586206895,
      "grad_norm": 0.6547107100486755,
      "learning_rate": 4.064960049765304e-05,
      "loss": 0.0622,
      "step": 267
    },
    {
      "epoch": 1.5402298850574714,
      "grad_norm": 0.41088828444480896,
      "learning_rate": 4.0576836991356566e-05,
      "loss": 0.0516,
      "step": 268
    },
    {
      "epoch": 1.5459770114942528,
      "grad_norm": 0.18591679632663727,
      "learning_rate": 4.050385715176334e-05,
      "loss": 0.024,
      "step": 269
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.15558525919914246,
      "learning_rate": 4.043066199242762e-05,
      "loss": 0.0136,
      "step": 270
    },
    {
      "epoch": 1.5574712643678161,
      "grad_norm": 0.16502735018730164,
      "learning_rate": 4.035725252989404e-05,
      "loss": 0.0115,
      "step": 271
    },
    {
      "epoch": 1.5632183908045976,
      "grad_norm": 0.18995028734207153,
      "learning_rate": 4.028362978368352e-05,
      "loss": 0.0134,
      "step": 272
    },
    {
      "epoch": 1.5689655172413794,
      "grad_norm": 0.14611458778381348,
      "learning_rate": 4.020979477627907e-05,
      "loss": 0.0192,
      "step": 273
    },
    {
      "epoch": 1.5747126436781609,
      "grad_norm": 0.3447577655315399,
      "learning_rate": 4.013574853311164e-05,
      "loss": 0.0357,
      "step": 274
    },
    {
      "epoch": 1.5804597701149425,
      "grad_norm": 0.10583726316690445,
      "learning_rate": 4.0061492082545835e-05,
      "loss": 0.0136,
      "step": 275
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.36231687664985657,
      "learning_rate": 3.998702645586565e-05,
      "loss": 0.0223,
      "step": 276
    },
    {
      "epoch": 1.5919540229885056,
      "grad_norm": 0.24283719062805176,
      "learning_rate": 3.9912352687260154e-05,
      "loss": 0.0191,
      "step": 277
    },
    {
      "epoch": 1.5977011494252875,
      "grad_norm": 0.8956915736198425,
      "learning_rate": 3.983747181380914e-05,
      "loss": 0.0484,
      "step": 278
    },
    {
      "epoch": 1.603448275862069,
      "grad_norm": 0.29115334153175354,
      "learning_rate": 3.976238487546864e-05,
      "loss": 0.0181,
      "step": 279
    },
    {
      "epoch": 1.6091954022988506,
      "grad_norm": 0.17697696387767792,
      "learning_rate": 3.9687092915056625e-05,
      "loss": 0.0213,
      "step": 280
    },
    {
      "epoch": 1.6149425287356323,
      "grad_norm": 0.39659038186073303,
      "learning_rate": 3.961159697823837e-05,
      "loss": 0.0242,
      "step": 281
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 0.42570123076438904,
      "learning_rate": 3.953589811351204e-05,
      "loss": 0.0651,
      "step": 282
    },
    {
      "epoch": 1.6264367816091954,
      "grad_norm": 0.5418093204498291,
      "learning_rate": 3.94599973721941e-05,
      "loss": 0.0257,
      "step": 283
    },
    {
      "epoch": 1.632183908045977,
      "grad_norm": 0.41252079606056213,
      "learning_rate": 3.938389580840468e-05,
      "loss": 0.0571,
      "step": 284
    },
    {
      "epoch": 1.6379310344827587,
      "grad_norm": 0.5317116975784302,
      "learning_rate": 3.930759447905298e-05,
      "loss": 0.0236,
      "step": 285
    },
    {
      "epoch": 1.6436781609195403,
      "grad_norm": 0.3516208529472351,
      "learning_rate": 3.923109444382254e-05,
      "loss": 0.0227,
      "step": 286
    },
    {
      "epoch": 1.6494252873563218,
      "grad_norm": 0.378749817609787,
      "learning_rate": 3.9154396765156596e-05,
      "loss": 0.0369,
      "step": 287
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.11803817003965378,
      "learning_rate": 3.907750250824327e-05,
      "loss": 0.0084,
      "step": 288
    },
    {
      "epoch": 1.660919540229885,
      "grad_norm": 0.6386761665344238,
      "learning_rate": 3.9000412741000766e-05,
      "loss": 0.0302,
      "step": 289
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.20013467967510223,
      "learning_rate": 3.892312853406261e-05,
      "loss": 0.0228,
      "step": 290
    },
    {
      "epoch": 1.6724137931034484,
      "grad_norm": 0.3525317311286926,
      "learning_rate": 3.884565096076269e-05,
      "loss": 0.0238,
      "step": 291
    },
    {
      "epoch": 1.6781609195402298,
      "grad_norm": 0.2217256873846054,
      "learning_rate": 3.876798109712041e-05,
      "loss": 0.0314,
      "step": 292
    },
    {
      "epoch": 1.6839080459770115,
      "grad_norm": 0.42553848028182983,
      "learning_rate": 3.869012002182573e-05,
      "loss": 0.0454,
      "step": 293
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 0.10149681568145752,
      "learning_rate": 3.861206881622419e-05,
      "loss": 0.0107,
      "step": 294
    },
    {
      "epoch": 1.6954022988505746,
      "grad_norm": 0.1004452258348465,
      "learning_rate": 3.8533828564301864e-05,
      "loss": 0.0067,
      "step": 295
    },
    {
      "epoch": 1.7011494252873565,
      "grad_norm": 0.30472832918167114,
      "learning_rate": 3.8455400352670365e-05,
      "loss": 0.0384,
      "step": 296
    },
    {
      "epoch": 1.706896551724138,
      "grad_norm": 0.3355861306190491,
      "learning_rate": 3.837678527055168e-05,
      "loss": 0.0118,
      "step": 297
    },
    {
      "epoch": 1.7126436781609196,
      "grad_norm": 0.6248414516448975,
      "learning_rate": 3.829798440976311e-05,
      "loss": 0.0963,
      "step": 298
    },
    {
      "epoch": 1.7183908045977012,
      "grad_norm": 0.3063965439796448,
      "learning_rate": 3.821899886470205e-05,
      "loss": 0.0427,
      "step": 299
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.4145275354385376,
      "learning_rate": 3.813982973233083e-05,
      "loss": 0.048,
      "step": 300
    },
    {
      "epoch": 1.7298850574712645,
      "grad_norm": 0.19328652322292328,
      "learning_rate": 3.806047811216146e-05,
      "loss": 0.0151,
      "step": 301
    },
    {
      "epoch": 1.735632183908046,
      "grad_norm": 0.16454648971557617,
      "learning_rate": 3.7980945106240365e-05,
      "loss": 0.0322,
      "step": 302
    },
    {
      "epoch": 1.7413793103448276,
      "grad_norm": 0.1849229484796524,
      "learning_rate": 3.7901231819133105e-05,
      "loss": 0.0149,
      "step": 303
    },
    {
      "epoch": 1.7471264367816093,
      "grad_norm": 0.3782241940498352,
      "learning_rate": 3.782133935790898e-05,
      "loss": 0.0277,
      "step": 304
    },
    {
      "epoch": 1.7528735632183907,
      "grad_norm": 0.14352382719516754,
      "learning_rate": 3.7741268832125686e-05,
      "loss": 0.0137,
      "step": 305
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 0.26338574290275574,
      "learning_rate": 3.766102135381393e-05,
      "loss": 0.0167,
      "step": 306
    },
    {
      "epoch": 1.764367816091954,
      "grad_norm": 0.44832709431648254,
      "learning_rate": 3.7580598037461935e-05,
      "loss": 0.0414,
      "step": 307
    },
    {
      "epoch": 1.7701149425287355,
      "grad_norm": 0.278956800699234,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0207,
      "step": 308
    },
    {
      "epoch": 1.7758620689655173,
      "grad_norm": 0.24398952722549438,
      "learning_rate": 3.741922836078499e-05,
      "loss": 0.0165,
      "step": 309
    },
    {
      "epoch": 1.7816091954022988,
      "grad_norm": 0.22732603549957275,
      "learning_rate": 3.7338284241584724e-05,
      "loss": 0.0158,
      "step": 310
    },
    {
      "epoch": 1.7873563218390804,
      "grad_norm": 0.74580979347229,
      "learning_rate": 3.7257168766562505e-05,
      "loss": 0.0614,
      "step": 311
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.2924332022666931,
      "learning_rate": 3.717588306226143e-05,
      "loss": 0.0332,
      "step": 312
    },
    {
      "epoch": 1.7988505747126435,
      "grad_norm": 0.1694021373987198,
      "learning_rate": 3.709442825758875e-05,
      "loss": 0.0156,
      "step": 313
    },
    {
      "epoch": 1.8045977011494254,
      "grad_norm": 0.2341812700033188,
      "learning_rate": 3.7012805483800214e-05,
      "loss": 0.0153,
      "step": 314
    },
    {
      "epoch": 1.8103448275862069,
      "grad_norm": 0.16142623126506805,
      "learning_rate": 3.693101587448436e-05,
      "loss": 0.0097,
      "step": 315
    },
    {
      "epoch": 1.8160919540229885,
      "grad_norm": 0.7943461537361145,
      "learning_rate": 3.684906056554675e-05,
      "loss": 0.1015,
      "step": 316
    },
    {
      "epoch": 1.8218390804597702,
      "grad_norm": 0.16499409079551697,
      "learning_rate": 3.67669406951942e-05,
      "loss": 0.0145,
      "step": 317
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 0.1443059742450714,
      "learning_rate": 3.6684657403919005e-05,
      "loss": 0.008,
      "step": 318
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.5233135223388672,
      "learning_rate": 3.660221183448304e-05,
      "loss": 0.0562,
      "step": 319
    },
    {
      "epoch": 1.839080459770115,
      "grad_norm": 0.47379085421562195,
      "learning_rate": 3.651960513190194e-05,
      "loss": 0.0243,
      "step": 320
    },
    {
      "epoch": 1.8448275862068966,
      "grad_norm": 0.253580242395401,
      "learning_rate": 3.6436838443429175e-05,
      "loss": 0.0235,
      "step": 321
    },
    {
      "epoch": 1.8505747126436782,
      "grad_norm": 0.4099176824092865,
      "learning_rate": 3.635391291854012e-05,
      "loss": 0.0431,
      "step": 322
    },
    {
      "epoch": 1.8563218390804597,
      "grad_norm": 0.12577787041664124,
      "learning_rate": 3.627082970891611e-05,
      "loss": 0.0098,
      "step": 323
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.44363147020339966,
      "learning_rate": 3.618758996842839e-05,
      "loss": 0.0561,
      "step": 324
    },
    {
      "epoch": 1.867816091954023,
      "grad_norm": 0.5296325087547302,
      "learning_rate": 3.6104194853122155e-05,
      "loss": 0.0416,
      "step": 325
    },
    {
      "epoch": 1.8735632183908046,
      "grad_norm": 0.30847641825675964,
      "learning_rate": 3.6020645521200476e-05,
      "loss": 0.0348,
      "step": 326
    },
    {
      "epoch": 1.8793103448275863,
      "grad_norm": 0.3006640374660492,
      "learning_rate": 3.5936943133008183e-05,
      "loss": 0.0396,
      "step": 327
    },
    {
      "epoch": 1.8850574712643677,
      "grad_norm": 0.19842948019504547,
      "learning_rate": 3.585308885101578e-05,
      "loss": 0.0216,
      "step": 328
    },
    {
      "epoch": 1.8908045977011494,
      "grad_norm": 0.3431902825832367,
      "learning_rate": 3.5769083839803294e-05,
      "loss": 0.016,
      "step": 329
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.4084427058696747,
      "learning_rate": 3.568492926604412e-05,
      "loss": 0.0358,
      "step": 330
    },
    {
      "epoch": 1.9022988505747125,
      "grad_norm": 0.5296233296394348,
      "learning_rate": 3.5600626298488756e-05,
      "loss": 0.0395,
      "step": 331
    },
    {
      "epoch": 1.9080459770114944,
      "grad_norm": 0.15465542674064636,
      "learning_rate": 3.551617610794866e-05,
      "loss": 0.0108,
      "step": 332
    },
    {
      "epoch": 1.9137931034482758,
      "grad_norm": 0.24824993312358856,
      "learning_rate": 3.5431579867279905e-05,
      "loss": 0.0185,
      "step": 333
    },
    {
      "epoch": 1.9195402298850575,
      "grad_norm": 0.4605512320995331,
      "learning_rate": 3.534683875136695e-05,
      "loss": 0.0141,
      "step": 334
    },
    {
      "epoch": 1.9252873563218391,
      "grad_norm": 0.3540666103363037,
      "learning_rate": 3.526195393710631e-05,
      "loss": 0.0142,
      "step": 335
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.5166353583335876,
      "learning_rate": 3.517692660339018e-05,
      "loss": 0.0462,
      "step": 336
    },
    {
      "epoch": 1.9367816091954024,
      "grad_norm": 0.25792184472084045,
      "learning_rate": 3.509175793109009e-05,
      "loss": 0.0165,
      "step": 337
    },
    {
      "epoch": 1.9425287356321839,
      "grad_norm": 0.7034411430358887,
      "learning_rate": 3.500644910304052e-05,
      "loss": 0.052,
      "step": 338
    },
    {
      "epoch": 1.9482758620689655,
      "grad_norm": 0.3218519985675812,
      "learning_rate": 3.492100130402242e-05,
      "loss": 0.0179,
      "step": 339
    },
    {
      "epoch": 1.9540229885057472,
      "grad_norm": 0.2934768795967102,
      "learning_rate": 3.483541572074682e-05,
      "loss": 0.0315,
      "step": 340
    },
    {
      "epoch": 1.9597701149425286,
      "grad_norm": 0.5159332156181335,
      "learning_rate": 3.47496935418383e-05,
      "loss": 0.0417,
      "step": 341
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 0.7631388902664185,
      "learning_rate": 3.4663835957818515e-05,
      "loss": 0.0252,
      "step": 342
    },
    {
      "epoch": 1.971264367816092,
      "grad_norm": 0.5379127264022827,
      "learning_rate": 3.4577844161089613e-05,
      "loss": 0.0336,
      "step": 343
    },
    {
      "epoch": 1.9770114942528736,
      "grad_norm": 0.2515622079372406,
      "learning_rate": 3.449171934591773e-05,
      "loss": 0.0224,
      "step": 344
    },
    {
      "epoch": 1.9827586206896552,
      "grad_norm": 0.5334444046020508,
      "learning_rate": 3.440546270841639e-05,
      "loss": 0.0276,
      "step": 345
    },
    {
      "epoch": 1.9885057471264367,
      "grad_norm": 0.3241370618343353,
      "learning_rate": 3.431907544652987e-05,
      "loss": 0.0222,
      "step": 346
    },
    {
      "epoch": 1.9942528735632183,
      "grad_norm": 0.2406899333000183,
      "learning_rate": 3.423255876001657e-05,
      "loss": 0.0194,
      "step": 347
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6717060804367065,
      "learning_rate": 3.414591385043237e-05,
      "loss": 0.0315,
      "step": 348
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.022634753957390785,
      "eval_runtime": 91.5576,
      "eval_samples_per_second": 0.961,
      "eval_steps_per_second": 0.481,
      "step": 348
    },
    {
      "epoch": 2.0057471264367814,
      "grad_norm": 0.3950808644294739,
      "learning_rate": 3.4059141921113926e-05,
      "loss": 0.0153,
      "step": 349
    },
    {
      "epoch": 2.0114942528735633,
      "grad_norm": 0.28782686591148376,
      "learning_rate": 3.397224417716197e-05,
      "loss": 0.0182,
      "step": 350
    },
    {
      "epoch": 2.0172413793103448,
      "grad_norm": 0.45559871196746826,
      "learning_rate": 3.3885221825424537e-05,
      "loss": 0.0187,
      "step": 351
    },
    {
      "epoch": 2.0229885057471266,
      "grad_norm": 0.38102272152900696,
      "learning_rate": 3.379807607448027e-05,
      "loss": 0.027,
      "step": 352
    },
    {
      "epoch": 2.028735632183908,
      "grad_norm": 0.12379895150661469,
      "learning_rate": 3.371080813462157e-05,
      "loss": 0.0057,
      "step": 353
    },
    {
      "epoch": 2.0344827586206895,
      "grad_norm": 0.8201534748077393,
      "learning_rate": 3.362341921783784e-05,
      "loss": 0.0563,
      "step": 354
    },
    {
      "epoch": 2.0402298850574714,
      "grad_norm": 0.12058958411216736,
      "learning_rate": 3.3535910537798585e-05,
      "loss": 0.0049,
      "step": 355
    },
    {
      "epoch": 2.045977011494253,
      "grad_norm": 0.1630365550518036,
      "learning_rate": 3.344828330983666e-05,
      "loss": 0.0096,
      "step": 356
    },
    {
      "epoch": 2.0517241379310347,
      "grad_norm": 0.6521601676940918,
      "learning_rate": 3.336053875093128e-05,
      "loss": 0.0486,
      "step": 357
    },
    {
      "epoch": 2.057471264367816,
      "grad_norm": 0.5124946236610413,
      "learning_rate": 3.3272678079691174e-05,
      "loss": 0.0208,
      "step": 358
    },
    {
      "epoch": 2.0632183908045976,
      "grad_norm": 0.3879086375236511,
      "learning_rate": 3.3184702516337684e-05,
      "loss": 0.0199,
      "step": 359
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 0.3126682639122009,
      "learning_rate": 3.309661328268776e-05,
      "loss": 0.018,
      "step": 360
    },
    {
      "epoch": 2.074712643678161,
      "grad_norm": 0.37594398856163025,
      "learning_rate": 3.3008411602137044e-05,
      "loss": 0.0189,
      "step": 361
    },
    {
      "epoch": 2.0804597701149423,
      "grad_norm": 0.3194340765476227,
      "learning_rate": 3.292009869964284e-05,
      "loss": 0.0284,
      "step": 362
    },
    {
      "epoch": 2.086206896551724,
      "grad_norm": 0.43566131591796875,
      "learning_rate": 3.283167580170712e-05,
      "loss": 0.0181,
      "step": 363
    },
    {
      "epoch": 2.0919540229885056,
      "grad_norm": 0.14060692489147186,
      "learning_rate": 3.27431441363595e-05,
      "loss": 0.01,
      "step": 364
    },
    {
      "epoch": 2.0977011494252875,
      "grad_norm": 0.19746777415275574,
      "learning_rate": 3.265450493314016e-05,
      "loss": 0.009,
      "step": 365
    },
    {
      "epoch": 2.103448275862069,
      "grad_norm": 0.17489413917064667,
      "learning_rate": 3.256575942308278e-05,
      "loss": 0.0101,
      "step": 366
    },
    {
      "epoch": 2.1091954022988504,
      "grad_norm": 0.31947061419487,
      "learning_rate": 3.247690883869746e-05,
      "loss": 0.0157,
      "step": 367
    },
    {
      "epoch": 2.1149425287356323,
      "grad_norm": 0.4457235634326935,
      "learning_rate": 3.238795441395357e-05,
      "loss": 0.0114,
      "step": 368
    },
    {
      "epoch": 2.1206896551724137,
      "grad_norm": 0.159192755818367,
      "learning_rate": 3.229889738426264e-05,
      "loss": 0.0074,
      "step": 369
    },
    {
      "epoch": 2.1264367816091956,
      "grad_norm": 0.45442995429039,
      "learning_rate": 3.2209738986461186e-05,
      "loss": 0.0124,
      "step": 370
    },
    {
      "epoch": 2.132183908045977,
      "grad_norm": 0.30595213174819946,
      "learning_rate": 3.2120480458793536e-05,
      "loss": 0.0149,
      "step": 371
    },
    {
      "epoch": 2.1379310344827585,
      "grad_norm": 0.549384593963623,
      "learning_rate": 3.203112304089466e-05,
      "loss": 0.0158,
      "step": 372
    },
    {
      "epoch": 2.1436781609195403,
      "grad_norm": 0.5473718643188477,
      "learning_rate": 3.194166797377289e-05,
      "loss": 0.0287,
      "step": 373
    },
    {
      "epoch": 2.1494252873563218,
      "grad_norm": 0.5737133622169495,
      "learning_rate": 3.185211649979275e-05,
      "loss": 0.0138,
      "step": 374
    },
    {
      "epoch": 2.1551724137931036,
      "grad_norm": 0.17178797721862793,
      "learning_rate": 3.176246986265767e-05,
      "loss": 0.0048,
      "step": 375
    },
    {
      "epoch": 2.160919540229885,
      "grad_norm": 0.701518714427948,
      "learning_rate": 3.167272930739272e-05,
      "loss": 0.0533,
      "step": 376
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.656316339969635,
      "learning_rate": 3.158289608032732e-05,
      "loss": 0.0222,
      "step": 377
    },
    {
      "epoch": 2.1724137931034484,
      "grad_norm": 0.4348108768463135,
      "learning_rate": 3.149297142907792e-05,
      "loss": 0.0077,
      "step": 378
    },
    {
      "epoch": 2.17816091954023,
      "grad_norm": 0.2765173017978668,
      "learning_rate": 3.14029566025307e-05,
      "loss": 0.0066,
      "step": 379
    },
    {
      "epoch": 2.1839080459770113,
      "grad_norm": 0.5723677277565002,
      "learning_rate": 3.1312852850824184e-05,
      "loss": 0.0184,
      "step": 380
    },
    {
      "epoch": 2.189655172413793,
      "grad_norm": 0.2914019823074341,
      "learning_rate": 3.122266142533191e-05,
      "loss": 0.0108,
      "step": 381
    },
    {
      "epoch": 2.1954022988505746,
      "grad_norm": 0.5965176224708557,
      "learning_rate": 3.113238357864505e-05,
      "loss": 0.0196,
      "step": 382
    },
    {
      "epoch": 2.2011494252873565,
      "grad_norm": 0.7961345314979553,
      "learning_rate": 3.104202056455501e-05,
      "loss": 0.0566,
      "step": 383
    },
    {
      "epoch": 2.206896551724138,
      "grad_norm": 0.2016075700521469,
      "learning_rate": 3.095157363803598e-05,
      "loss": 0.0065,
      "step": 384
    },
    {
      "epoch": 2.2126436781609193,
      "grad_norm": 0.5500932931900024,
      "learning_rate": 3.086104405522758e-05,
      "loss": 0.0232,
      "step": 385
    },
    {
      "epoch": 2.218390804597701,
      "grad_norm": 0.6224250793457031,
      "learning_rate": 3.077043307341735e-05,
      "loss": 0.0311,
      "step": 386
    },
    {
      "epoch": 2.2241379310344827,
      "grad_norm": 0.7657910585403442,
      "learning_rate": 3.06797419510233e-05,
      "loss": 0.036,
      "step": 387
    },
    {
      "epoch": 2.2298850574712645,
      "grad_norm": 0.584283173084259,
      "learning_rate": 3.0588971947576465e-05,
      "loss": 0.0336,
      "step": 388
    },
    {
      "epoch": 2.235632183908046,
      "grad_norm": 0.33944663405418396,
      "learning_rate": 3.0498124323703393e-05,
      "loss": 0.014,
      "step": 389
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 0.1694667786359787,
      "learning_rate": 3.0407200341108617e-05,
      "loss": 0.0051,
      "step": 390
    },
    {
      "epoch": 2.2471264367816093,
      "grad_norm": 0.5021709203720093,
      "learning_rate": 3.0316201262557153e-05,
      "loss": 0.0162,
      "step": 391
    },
    {
      "epoch": 2.2528735632183907,
      "grad_norm": 0.5500501990318298,
      "learning_rate": 3.0225128351856974e-05,
      "loss": 0.0204,
      "step": 392
    },
    {
      "epoch": 2.2586206896551726,
      "grad_norm": 2.168248414993286,
      "learning_rate": 3.013398287384144e-05,
      "loss": 0.1269,
      "step": 393
    },
    {
      "epoch": 2.264367816091954,
      "grad_norm": 0.4202249348163605,
      "learning_rate": 3.0042766094351722e-05,
      "loss": 0.0125,
      "step": 394
    },
    {
      "epoch": 2.2701149425287355,
      "grad_norm": 0.22607426345348358,
      "learning_rate": 2.9951479280219253e-05,
      "loss": 0.0126,
      "step": 395
    },
    {
      "epoch": 2.2758620689655173,
      "grad_norm": 0.28793463110923767,
      "learning_rate": 2.986012369924811e-05,
      "loss": 0.0156,
      "step": 396
    },
    {
      "epoch": 2.281609195402299,
      "grad_norm": 0.5015022158622742,
      "learning_rate": 2.976870062019741e-05,
      "loss": 0.0364,
      "step": 397
    },
    {
      "epoch": 2.2873563218390807,
      "grad_norm": 0.5242546200752258,
      "learning_rate": 2.9677211312763698e-05,
      "loss": 0.0475,
      "step": 398
    },
    {
      "epoch": 2.293103448275862,
      "grad_norm": 0.7603775858879089,
      "learning_rate": 2.9585657047563315e-05,
      "loss": 0.0386,
      "step": 399
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 0.4055424630641937,
      "learning_rate": 2.949403909611472e-05,
      "loss": 0.0297,
      "step": 400
    },
    {
      "epoch": 2.3045977011494254,
      "grad_norm": 0.2050214558839798,
      "learning_rate": 2.9402358730820894e-05,
      "loss": 0.0152,
      "step": 401
    },
    {
      "epoch": 2.310344827586207,
      "grad_norm": 0.5749786496162415,
      "learning_rate": 2.931061722495159e-05,
      "loss": 0.0312,
      "step": 402
    },
    {
      "epoch": 2.3160919540229887,
      "grad_norm": 0.4458301365375519,
      "learning_rate": 2.9218815852625713e-05,
      "loss": 0.0489,
      "step": 403
    },
    {
      "epoch": 2.32183908045977,
      "grad_norm": 0.2783806324005127,
      "learning_rate": 2.91269558887936e-05,
      "loss": 0.0147,
      "step": 404
    },
    {
      "epoch": 2.3275862068965516,
      "grad_norm": 0.6374253034591675,
      "learning_rate": 2.9035038609219306e-05,
      "loss": 0.0839,
      "step": 405
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.3883012533187866,
      "learning_rate": 2.8943065290462907e-05,
      "loss": 0.0441,
      "step": 406
    },
    {
      "epoch": 2.339080459770115,
      "grad_norm": 0.3611263334751129,
      "learning_rate": 2.8851037209862746e-05,
      "loss": 0.0398,
      "step": 407
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 0.16486185789108276,
      "learning_rate": 2.875895564551772e-05,
      "loss": 0.0116,
      "step": 408
    },
    {
      "epoch": 2.3505747126436782,
      "grad_norm": 0.20515839755535126,
      "learning_rate": 2.866682187626951e-05,
      "loss": 0.0175,
      "step": 409
    },
    {
      "epoch": 2.3563218390804597,
      "grad_norm": 0.12537655234336853,
      "learning_rate": 2.8574637181684817e-05,
      "loss": 0.0097,
      "step": 410
    },
    {
      "epoch": 2.3620689655172415,
      "grad_norm": 0.18509624898433685,
      "learning_rate": 2.8482402842037614e-05,
      "loss": 0.0183,
      "step": 411
    },
    {
      "epoch": 2.367816091954023,
      "grad_norm": 0.3513887822628021,
      "learning_rate": 2.839012013829134e-05,
      "loss": 0.0463,
      "step": 412
    },
    {
      "epoch": 2.3735632183908044,
      "grad_norm": 0.16680896282196045,
      "learning_rate": 2.8297790352081128e-05,
      "loss": 0.0136,
      "step": 413
    },
    {
      "epoch": 2.3793103448275863,
      "grad_norm": 0.2446347326040268,
      "learning_rate": 2.8205414765696003e-05,
      "loss": 0.0175,
      "step": 414
    },
    {
      "epoch": 2.3850574712643677,
      "grad_norm": 0.2788975238800049,
      "learning_rate": 2.8112994662061064e-05,
      "loss": 0.0318,
      "step": 415
    },
    {
      "epoch": 2.3908045977011496,
      "grad_norm": 0.07330638915300369,
      "learning_rate": 2.8020531324719674e-05,
      "loss": 0.0122,
      "step": 416
    },
    {
      "epoch": 2.396551724137931,
      "grad_norm": 0.5485195517539978,
      "learning_rate": 2.792802603781562e-05,
      "loss": 0.0519,
      "step": 417
    },
    {
      "epoch": 2.4022988505747125,
      "grad_norm": 0.16489312052726746,
      "learning_rate": 2.7835480086075305e-05,
      "loss": 0.015,
      "step": 418
    },
    {
      "epoch": 2.4080459770114944,
      "grad_norm": 0.42366138100624084,
      "learning_rate": 2.7742894754789882e-05,
      "loss": 0.0342,
      "step": 419
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 0.2546347975730896,
      "learning_rate": 2.7650271329797427e-05,
      "loss": 0.0263,
      "step": 420
    },
    {
      "epoch": 2.4195402298850572,
      "grad_norm": 0.3120303153991699,
      "learning_rate": 2.755761109746505e-05,
      "loss": 0.0268,
      "step": 421
    },
    {
      "epoch": 2.425287356321839,
      "grad_norm": 0.19193649291992188,
      "learning_rate": 2.7464915344671048e-05,
      "loss": 0.0277,
      "step": 422
    },
    {
      "epoch": 2.4310344827586206,
      "grad_norm": 0.19267083704471588,
      "learning_rate": 2.737218535878705e-05,
      "loss": 0.0157,
      "step": 423
    },
    {
      "epoch": 2.4367816091954024,
      "grad_norm": 0.22024497389793396,
      "learning_rate": 2.727942242766009e-05,
      "loss": 0.0136,
      "step": 424
    },
    {
      "epoch": 2.442528735632184,
      "grad_norm": 0.2876212000846863,
      "learning_rate": 2.718662783959478e-05,
      "loss": 0.0218,
      "step": 425
    },
    {
      "epoch": 2.4482758620689653,
      "grad_norm": 0.19681233167648315,
      "learning_rate": 2.7093802883335357e-05,
      "loss": 0.0138,
      "step": 426
    },
    {
      "epoch": 2.454022988505747,
      "grad_norm": 0.14387983083724976,
      "learning_rate": 2.700094884804784e-05,
      "loss": 0.0158,
      "step": 427
    },
    {
      "epoch": 2.4597701149425286,
      "grad_norm": 0.25755372643470764,
      "learning_rate": 2.6908067023302097e-05,
      "loss": 0.0257,
      "step": 428
    },
    {
      "epoch": 2.4655172413793105,
      "grad_norm": 0.2626495659351349,
      "learning_rate": 2.6815158699053932e-05,
      "loss": 0.0315,
      "step": 429
    },
    {
      "epoch": 2.471264367816092,
      "grad_norm": 0.26310187578201294,
      "learning_rate": 2.672222516562719e-05,
      "loss": 0.017,
      "step": 430
    },
    {
      "epoch": 2.4770114942528734,
      "grad_norm": 0.18335853517055511,
      "learning_rate": 2.6629267713695805e-05,
      "loss": 0.0178,
      "step": 431
    },
    {
      "epoch": 2.4827586206896552,
      "grad_norm": 0.2952478229999542,
      "learning_rate": 2.6536287634265918e-05,
      "loss": 0.0165,
      "step": 432
    },
    {
      "epoch": 2.4885057471264367,
      "grad_norm": 0.3772375285625458,
      "learning_rate": 2.64432862186579e-05,
      "loss": 0.0279,
      "step": 433
    },
    {
      "epoch": 2.4942528735632186,
      "grad_norm": 0.16344556212425232,
      "learning_rate": 2.635026475848846e-05,
      "loss": 0.0101,
      "step": 434
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5477245450019836,
      "learning_rate": 2.6257224545652688e-05,
      "loss": 0.0519,
      "step": 435
    },
    {
      "epoch": 2.5057471264367814,
      "grad_norm": 0.13361407816410065,
      "learning_rate": 2.6164166872306096e-05,
      "loss": 0.0201,
      "step": 436
    },
    {
      "epoch": 2.5114942528735633,
      "grad_norm": 0.4236428141593933,
      "learning_rate": 2.6071093030846717e-05,
      "loss": 0.0342,
      "step": 437
    },
    {
      "epoch": 2.5172413793103448,
      "grad_norm": 0.1331983357667923,
      "learning_rate": 2.5978004313897104e-05,
      "loss": 0.0235,
      "step": 438
    },
    {
      "epoch": 2.5229885057471266,
      "grad_norm": 0.20111821591854095,
      "learning_rate": 2.5884902014286416e-05,
      "loss": 0.0203,
      "step": 439
    },
    {
      "epoch": 2.528735632183908,
      "grad_norm": 0.28364571928977966,
      "learning_rate": 2.579178742503245e-05,
      "loss": 0.0272,
      "step": 440
    },
    {
      "epoch": 2.5344827586206895,
      "grad_norm": 0.3875006437301636,
      "learning_rate": 2.569866183932368e-05,
      "loss": 0.0231,
      "step": 441
    },
    {
      "epoch": 2.5402298850574714,
      "grad_norm": 0.10407587140798569,
      "learning_rate": 2.5605526550501297e-05,
      "loss": 0.0096,
      "step": 442
    },
    {
      "epoch": 2.545977011494253,
      "grad_norm": 0.17411860823631287,
      "learning_rate": 2.551238285204126e-05,
      "loss": 0.0161,
      "step": 443
    },
    {
      "epoch": 2.5517241379310347,
      "grad_norm": 0.30295494198799133,
      "learning_rate": 2.5419232037536316e-05,
      "loss": 0.0299,
      "step": 444
    },
    {
      "epoch": 2.557471264367816,
      "grad_norm": 0.5433998703956604,
      "learning_rate": 2.5326075400678036e-05,
      "loss": 0.0482,
      "step": 445
    },
    {
      "epoch": 2.5632183908045976,
      "grad_norm": 0.16919919848442078,
      "learning_rate": 2.5232914235238863e-05,
      "loss": 0.0104,
      "step": 446
    },
    {
      "epoch": 2.5689655172413794,
      "grad_norm": 0.4159778952598572,
      "learning_rate": 2.5139749835054123e-05,
      "loss": 0.0327,
      "step": 447
    },
    {
      "epoch": 2.574712643678161,
      "grad_norm": 0.44434309005737305,
      "learning_rate": 2.5046583494004077e-05,
      "loss": 0.0302,
      "step": 448
    },
    {
      "epoch": 2.5804597701149428,
      "grad_norm": 0.39002296328544617,
      "learning_rate": 2.4953416505995925e-05,
      "loss": 0.0334,
      "step": 449
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.4366905987262726,
      "learning_rate": 2.4860250164945876e-05,
      "loss": 0.0323,
      "step": 450
    },
    {
      "epoch": 2.5919540229885056,
      "grad_norm": 0.13467717170715332,
      "learning_rate": 2.476708576476114e-05,
      "loss": 0.0133,
      "step": 451
    },
    {
      "epoch": 2.5977011494252875,
      "grad_norm": 0.24252791702747345,
      "learning_rate": 2.4673924599321963e-05,
      "loss": 0.0234,
      "step": 452
    },
    {
      "epoch": 2.603448275862069,
      "grad_norm": 0.3848288655281067,
      "learning_rate": 2.4580767962463687e-05,
      "loss": 0.026,
      "step": 453
    },
    {
      "epoch": 2.609195402298851,
      "grad_norm": 0.10643648356199265,
      "learning_rate": 2.448761714795874e-05,
      "loss": 0.0044,
      "step": 454
    },
    {
      "epoch": 2.6149425287356323,
      "grad_norm": 0.17027154564857483,
      "learning_rate": 2.4394473449498702e-05,
      "loss": 0.0112,
      "step": 455
    },
    {
      "epoch": 2.6206896551724137,
      "grad_norm": 0.4473627507686615,
      "learning_rate": 2.4301338160676324e-05,
      "loss": 0.0322,
      "step": 456
    },
    {
      "epoch": 2.626436781609195,
      "grad_norm": 0.5602700114250183,
      "learning_rate": 2.4208212574967553e-05,
      "loss": 0.0369,
      "step": 457
    },
    {
      "epoch": 2.632183908045977,
      "grad_norm": 0.26621732115745544,
      "learning_rate": 2.411509798571359e-05,
      "loss": 0.0215,
      "step": 458
    },
    {
      "epoch": 2.637931034482759,
      "grad_norm": 0.3829457461833954,
      "learning_rate": 2.40219956861029e-05,
      "loss": 0.0259,
      "step": 459
    },
    {
      "epoch": 2.6436781609195403,
      "grad_norm": 0.23823630809783936,
      "learning_rate": 2.392890696915329e-05,
      "loss": 0.0125,
      "step": 460
    },
    {
      "epoch": 2.6494252873563218,
      "grad_norm": 0.29139968752861023,
      "learning_rate": 2.3835833127693906e-05,
      "loss": 0.0172,
      "step": 461
    },
    {
      "epoch": 2.655172413793103,
      "grad_norm": 0.17751553654670715,
      "learning_rate": 2.374277545434732e-05,
      "loss": 0.0164,
      "step": 462
    },
    {
      "epoch": 2.660919540229885,
      "grad_norm": 0.5117390155792236,
      "learning_rate": 2.3649735241511547e-05,
      "loss": 0.0379,
      "step": 463
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.8360591530799866,
      "learning_rate": 2.3556713781342106e-05,
      "loss": 0.0591,
      "step": 464
    },
    {
      "epoch": 2.6724137931034484,
      "grad_norm": 0.23252558708190918,
      "learning_rate": 2.346371236573409e-05,
      "loss": 0.0093,
      "step": 465
    },
    {
      "epoch": 2.67816091954023,
      "grad_norm": 0.4174315333366394,
      "learning_rate": 2.33707322863042e-05,
      "loss": 0.0207,
      "step": 466
    },
    {
      "epoch": 2.6839080459770113,
      "grad_norm": 0.16741010546684265,
      "learning_rate": 2.3277774834372818e-05,
      "loss": 0.006,
      "step": 467
    },
    {
      "epoch": 2.689655172413793,
      "grad_norm": 0.4066106081008911,
      "learning_rate": 2.318484130094607e-05,
      "loss": 0.0133,
      "step": 468
    },
    {
      "epoch": 2.6954022988505746,
      "grad_norm": 0.6339190006256104,
      "learning_rate": 2.309193297669791e-05,
      "loss": 0.0288,
      "step": 469
    },
    {
      "epoch": 2.7011494252873565,
      "grad_norm": 0.5667998194694519,
      "learning_rate": 2.2999051151952165e-05,
      "loss": 0.0387,
      "step": 470
    },
    {
      "epoch": 2.706896551724138,
      "grad_norm": 0.35807716846466064,
      "learning_rate": 2.2906197116664653e-05,
      "loss": 0.0291,
      "step": 471
    },
    {
      "epoch": 2.7126436781609193,
      "grad_norm": 0.11191453039646149,
      "learning_rate": 2.2813372160405232e-05,
      "loss": 0.0046,
      "step": 472
    },
    {
      "epoch": 2.718390804597701,
      "grad_norm": 0.08712491393089294,
      "learning_rate": 2.2720577572339913e-05,
      "loss": 0.0047,
      "step": 473
    },
    {
      "epoch": 2.7241379310344827,
      "grad_norm": 0.6778643727302551,
      "learning_rate": 2.262781464121296e-05,
      "loss": 0.0493,
      "step": 474
    },
    {
      "epoch": 2.7298850574712645,
      "grad_norm": 0.18444108963012695,
      "learning_rate": 2.2535084655328954e-05,
      "loss": 0.0081,
      "step": 475
    },
    {
      "epoch": 2.735632183908046,
      "grad_norm": 0.583599865436554,
      "learning_rate": 2.2442388902534958e-05,
      "loss": 0.0301,
      "step": 476
    },
    {
      "epoch": 2.7413793103448274,
      "grad_norm": 0.2624463737010956,
      "learning_rate": 2.2349728670202582e-05,
      "loss": 0.0126,
      "step": 477
    },
    {
      "epoch": 2.7471264367816093,
      "grad_norm": 0.19821958243846893,
      "learning_rate": 2.225710524521012e-05,
      "loss": 0.0111,
      "step": 478
    },
    {
      "epoch": 2.7528735632183907,
      "grad_norm": 0.40767067670822144,
      "learning_rate": 2.2164519913924697e-05,
      "loss": 0.0183,
      "step": 479
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 0.253496378660202,
      "learning_rate": 2.2071973962184384e-05,
      "loss": 0.0129,
      "step": 480
    },
    {
      "epoch": 2.764367816091954,
      "grad_norm": 0.13235697150230408,
      "learning_rate": 2.1979468675280328e-05,
      "loss": 0.0075,
      "step": 481
    },
    {
      "epoch": 2.7701149425287355,
      "grad_norm": 0.4945787191390991,
      "learning_rate": 2.1887005337938935e-05,
      "loss": 0.0273,
      "step": 482
    },
    {
      "epoch": 2.7758620689655173,
      "grad_norm": 0.766806423664093,
      "learning_rate": 2.1794585234303993e-05,
      "loss": 0.0514,
      "step": 483
    },
    {
      "epoch": 2.781609195402299,
      "grad_norm": 0.2559971511363983,
      "learning_rate": 2.170220964791887e-05,
      "loss": 0.0116,
      "step": 484
    },
    {
      "epoch": 2.7873563218390807,
      "grad_norm": 0.17486122250556946,
      "learning_rate": 2.1609879861708664e-05,
      "loss": 0.0076,
      "step": 485
    },
    {
      "epoch": 2.793103448275862,
      "grad_norm": 0.4618547856807709,
      "learning_rate": 2.1517597157962392e-05,
      "loss": 0.0332,
      "step": 486
    },
    {
      "epoch": 2.7988505747126435,
      "grad_norm": 0.5830840468406677,
      "learning_rate": 2.1425362818315186e-05,
      "loss": 0.029,
      "step": 487
    },
    {
      "epoch": 2.8045977011494254,
      "grad_norm": 0.1684401035308838,
      "learning_rate": 2.1333178123730498e-05,
      "loss": 0.0056,
      "step": 488
    },
    {
      "epoch": 2.810344827586207,
      "grad_norm": 0.19313053786754608,
      "learning_rate": 2.124104435448228e-05,
      "loss": 0.0105,
      "step": 489
    },
    {
      "epoch": 2.8160919540229887,
      "grad_norm": 0.5136148929595947,
      "learning_rate": 2.114896279013726e-05,
      "loss": 0.03,
      "step": 490
    },
    {
      "epoch": 2.82183908045977,
      "grad_norm": 0.28596821427345276,
      "learning_rate": 2.1056934709537102e-05,
      "loss": 0.011,
      "step": 491
    },
    {
      "epoch": 2.8275862068965516,
      "grad_norm": 0.27703753113746643,
      "learning_rate": 2.0964961390780703e-05,
      "loss": 0.0117,
      "step": 492
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 0.26612967252731323,
      "learning_rate": 2.0873044111206405e-05,
      "loss": 0.0233,
      "step": 493
    },
    {
      "epoch": 2.839080459770115,
      "grad_norm": 0.13272669911384583,
      "learning_rate": 2.078118414737429e-05,
      "loss": 0.0049,
      "step": 494
    },
    {
      "epoch": 2.844827586206897,
      "grad_norm": 0.5078458189964294,
      "learning_rate": 2.0689382775048418e-05,
      "loss": 0.0229,
      "step": 495
    },
    {
      "epoch": 2.8505747126436782,
      "grad_norm": 0.5808330774307251,
      "learning_rate": 2.059764126917911e-05,
      "loss": 0.0225,
      "step": 496
    },
    {
      "epoch": 2.8563218390804597,
      "grad_norm": 0.1856093555688858,
      "learning_rate": 2.050596090388528e-05,
      "loss": 0.0182,
      "step": 497
    },
    {
      "epoch": 2.862068965517241,
      "grad_norm": 0.11125695705413818,
      "learning_rate": 2.0414342952436694e-05,
      "loss": 0.0101,
      "step": 498
    },
    {
      "epoch": 2.867816091954023,
      "grad_norm": 0.2280559092760086,
      "learning_rate": 2.0322788687236308e-05,
      "loss": 0.012,
      "step": 499
    },
    {
      "epoch": 2.873563218390805,
      "grad_norm": 0.18899068236351013,
      "learning_rate": 2.02312993798026e-05,
      "loss": 0.0091,
      "step": 500
    },
    {
      "epoch": 2.8793103448275863,
      "grad_norm": 0.32288509607315063,
      "learning_rate": 2.0139876300751904e-05,
      "loss": 0.0111,
      "step": 501
    },
    {
      "epoch": 2.8850574712643677,
      "grad_norm": 0.49849629402160645,
      "learning_rate": 2.004852071978076e-05,
      "loss": 0.0185,
      "step": 502
    },
    {
      "epoch": 2.890804597701149,
      "grad_norm": 0.29536759853363037,
      "learning_rate": 1.995723390564829e-05,
      "loss": 0.0151,
      "step": 503
    },
    {
      "epoch": 2.896551724137931,
      "grad_norm": 0.07518059760332108,
      "learning_rate": 1.9866017126158574e-05,
      "loss": 0.0032,
      "step": 504
    },
    {
      "epoch": 2.9022988505747125,
      "grad_norm": 0.4954320192337036,
      "learning_rate": 1.9774871648143035e-05,
      "loss": 0.0333,
      "step": 505
    },
    {
      "epoch": 2.9080459770114944,
      "grad_norm": 0.15562377870082855,
      "learning_rate": 1.9683798737442856e-05,
      "loss": 0.0061,
      "step": 506
    },
    {
      "epoch": 2.913793103448276,
      "grad_norm": 0.7147036790847778,
      "learning_rate": 1.9592799658891385e-05,
      "loss": 0.0318,
      "step": 507
    },
    {
      "epoch": 2.9195402298850572,
      "grad_norm": 0.5231574773788452,
      "learning_rate": 1.9501875676296606e-05,
      "loss": 0.0289,
      "step": 508
    },
    {
      "epoch": 2.925287356321839,
      "grad_norm": 0.7124300003051758,
      "learning_rate": 1.9411028052423534e-05,
      "loss": 0.0256,
      "step": 509
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 0.4116665720939636,
      "learning_rate": 1.9320258048976702e-05,
      "loss": 0.0171,
      "step": 510
    },
    {
      "epoch": 2.9367816091954024,
      "grad_norm": 0.08443867415189743,
      "learning_rate": 1.922956692658266e-05,
      "loss": 0.0027,
      "step": 511
    },
    {
      "epoch": 2.942528735632184,
      "grad_norm": 0.4028300642967224,
      "learning_rate": 1.9138955944772426e-05,
      "loss": 0.0256,
      "step": 512
    },
    {
      "epoch": 2.9482758620689653,
      "grad_norm": 0.1687060445547104,
      "learning_rate": 1.904842636196402e-05,
      "loss": 0.0082,
      "step": 513
    },
    {
      "epoch": 2.954022988505747,
      "grad_norm": 1.1308231353759766,
      "learning_rate": 1.8957979435444998e-05,
      "loss": 0.0507,
      "step": 514
    },
    {
      "epoch": 2.9597701149425286,
      "grad_norm": 0.35801228880882263,
      "learning_rate": 1.886761642135495e-05,
      "loss": 0.0094,
      "step": 515
    },
    {
      "epoch": 2.9655172413793105,
      "grad_norm": 0.29129233956336975,
      "learning_rate": 1.8777338574668095e-05,
      "loss": 0.0113,
      "step": 516
    },
    {
      "epoch": 2.971264367816092,
      "grad_norm": 0.20808587968349457,
      "learning_rate": 1.8687147149175825e-05,
      "loss": 0.0102,
      "step": 517
    },
    {
      "epoch": 2.9770114942528734,
      "grad_norm": 0.24244624376296997,
      "learning_rate": 1.8597043397469305e-05,
      "loss": 0.0078,
      "step": 518
    },
    {
      "epoch": 2.9827586206896552,
      "grad_norm": 0.3712000548839569,
      "learning_rate": 1.850702857092208e-05,
      "loss": 0.0132,
      "step": 519
    },
    {
      "epoch": 2.9885057471264367,
      "grad_norm": 1.1104086637496948,
      "learning_rate": 1.8417103919672685e-05,
      "loss": 0.0557,
      "step": 520
    },
    {
      "epoch": 2.9942528735632186,
      "grad_norm": 0.8292294144630432,
      "learning_rate": 1.8327270692607285e-05,
      "loss": 0.0295,
      "step": 521
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.157335638999939,
      "learning_rate": 1.8237530137342335e-05,
      "loss": 0.0288,
      "step": 522
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.023683788254857063,
      "eval_runtime": 91.0226,
      "eval_samples_per_second": 0.967,
      "eval_steps_per_second": 0.483,
      "step": 522
    },
    {
      "epoch": 3.0057471264367814,
      "grad_norm": 1.209127426147461,
      "learning_rate": 1.8147883500207256e-05,
      "loss": 0.0362,
      "step": 523
    },
    {
      "epoch": 3.0114942528735633,
      "grad_norm": 0.27931326627731323,
      "learning_rate": 1.8058332026227122e-05,
      "loss": 0.0072,
      "step": 524
    },
    {
      "epoch": 3.0172413793103448,
      "grad_norm": 0.1659775972366333,
      "learning_rate": 1.796887695910535e-05,
      "loss": 0.0057,
      "step": 525
    },
    {
      "epoch": 3.0229885057471266,
      "grad_norm": 0.40947580337524414,
      "learning_rate": 1.787951954120647e-05,
      "loss": 0.0123,
      "step": 526
    },
    {
      "epoch": 3.028735632183908,
      "grad_norm": 0.036786407232284546,
      "learning_rate": 1.7790261013538824e-05,
      "loss": 0.0015,
      "step": 527
    },
    {
      "epoch": 3.0344827586206895,
      "grad_norm": 0.8051783442497253,
      "learning_rate": 1.7701102615737368e-05,
      "loss": 0.0248,
      "step": 528
    },
    {
      "epoch": 3.0402298850574714,
      "grad_norm": 0.700654149055481,
      "learning_rate": 1.761204558604644e-05,
      "loss": 0.0262,
      "step": 529
    },
    {
      "epoch": 3.045977011494253,
      "grad_norm": 0.9721000790596008,
      "learning_rate": 1.752309116130255e-05,
      "loss": 0.0486,
      "step": 530
    },
    {
      "epoch": 3.0517241379310347,
      "grad_norm": 0.3416164815425873,
      "learning_rate": 1.7434240576917226e-05,
      "loss": 0.0117,
      "step": 531
    },
    {
      "epoch": 3.057471264367816,
      "grad_norm": 0.4190163314342499,
      "learning_rate": 1.7345495066859853e-05,
      "loss": 0.0183,
      "step": 532
    },
    {
      "epoch": 3.0632183908045976,
      "grad_norm": 0.4058409333229065,
      "learning_rate": 1.725685586364051e-05,
      "loss": 0.0177,
      "step": 533
    },
    {
      "epoch": 3.0689655172413794,
      "grad_norm": 0.3643544912338257,
      "learning_rate": 1.7168324198292888e-05,
      "loss": 0.0102,
      "step": 534
    },
    {
      "epoch": 3.074712643678161,
      "grad_norm": 0.14642146229743958,
      "learning_rate": 1.707990130035717e-05,
      "loss": 0.0067,
      "step": 535
    },
    {
      "epoch": 3.0804597701149423,
      "grad_norm": 0.5541799068450928,
      "learning_rate": 1.6991588397862955e-05,
      "loss": 0.036,
      "step": 536
    },
    {
      "epoch": 3.086206896551724,
      "grad_norm": 0.23340751230716705,
      "learning_rate": 1.6903386717312236e-05,
      "loss": 0.0177,
      "step": 537
    },
    {
      "epoch": 3.0919540229885056,
      "grad_norm": 0.06695874780416489,
      "learning_rate": 1.6815297483662318e-05,
      "loss": 0.0036,
      "step": 538
    },
    {
      "epoch": 3.0977011494252875,
      "grad_norm": 0.3287580609321594,
      "learning_rate": 1.6727321920308825e-05,
      "loss": 0.0137,
      "step": 539
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 0.7666414976119995,
      "learning_rate": 1.6639461249068726e-05,
      "loss": 0.0258,
      "step": 540
    },
    {
      "epoch": 3.1091954022988504,
      "grad_norm": 0.4882209897041321,
      "learning_rate": 1.6551716690163343e-05,
      "loss": 0.03,
      "step": 541
    },
    {
      "epoch": 3.1149425287356323,
      "grad_norm": 0.2237003892660141,
      "learning_rate": 1.6464089462201414e-05,
      "loss": 0.0113,
      "step": 542
    },
    {
      "epoch": 3.1206896551724137,
      "grad_norm": 0.27877935767173767,
      "learning_rate": 1.637658078216217e-05,
      "loss": 0.0111,
      "step": 543
    },
    {
      "epoch": 3.1264367816091956,
      "grad_norm": 0.1319291740655899,
      "learning_rate": 1.6289191865378433e-05,
      "loss": 0.0055,
      "step": 544
    },
    {
      "epoch": 3.132183908045977,
      "grad_norm": 0.5980613827705383,
      "learning_rate": 1.620192392551974e-05,
      "loss": 0.0261,
      "step": 545
    },
    {
      "epoch": 3.1379310344827585,
      "grad_norm": 0.27575215697288513,
      "learning_rate": 1.6114778174575473e-05,
      "loss": 0.017,
      "step": 546
    },
    {
      "epoch": 3.1436781609195403,
      "grad_norm": 0.18921077251434326,
      "learning_rate": 1.602775582283804e-05,
      "loss": 0.0068,
      "step": 547
    },
    {
      "epoch": 3.1494252873563218,
      "grad_norm": 0.10128005594015121,
      "learning_rate": 1.594085807888608e-05,
      "loss": 0.0052,
      "step": 548
    },
    {
      "epoch": 3.1551724137931036,
      "grad_norm": 0.5547107458114624,
      "learning_rate": 1.585408614956763e-05,
      "loss": 0.0191,
      "step": 549
    },
    {
      "epoch": 3.160919540229885,
      "grad_norm": 0.9556652903556824,
      "learning_rate": 1.5767441239983434e-05,
      "loss": 0.0459,
      "step": 550
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 0.13824576139450073,
      "learning_rate": 1.5680924553470132e-05,
      "loss": 0.0097,
      "step": 551
    },
    {
      "epoch": 3.1724137931034484,
      "grad_norm": 0.7255656719207764,
      "learning_rate": 1.559453729158361e-05,
      "loss": 0.0389,
      "step": 552
    },
    {
      "epoch": 3.17816091954023,
      "grad_norm": 0.4150945246219635,
      "learning_rate": 1.5508280654082268e-05,
      "loss": 0.0205,
      "step": 553
    },
    {
      "epoch": 3.1839080459770113,
      "grad_norm": 0.16090096533298492,
      "learning_rate": 1.5422155838910396e-05,
      "loss": 0.0071,
      "step": 554
    },
    {
      "epoch": 3.189655172413793,
      "grad_norm": 0.5734550952911377,
      "learning_rate": 1.5336164042181494e-05,
      "loss": 0.0348,
      "step": 555
    },
    {
      "epoch": 3.1954022988505746,
      "grad_norm": 0.30510246753692627,
      "learning_rate": 1.52503064581617e-05,
      "loss": 0.0141,
      "step": 556
    },
    {
      "epoch": 3.2011494252873565,
      "grad_norm": 0.5022398233413696,
      "learning_rate": 1.5164584279253185e-05,
      "loss": 0.0258,
      "step": 557
    },
    {
      "epoch": 3.206896551724138,
      "grad_norm": 0.5495998859405518,
      "learning_rate": 1.5078998695977586e-05,
      "loss": 0.0445,
      "step": 558
    },
    {
      "epoch": 3.2126436781609193,
      "grad_norm": 0.26761260628700256,
      "learning_rate": 1.4993550896959497e-05,
      "loss": 0.0105,
      "step": 559
    },
    {
      "epoch": 3.218390804597701,
      "grad_norm": 0.4198656678199768,
      "learning_rate": 1.4908242068909922e-05,
      "loss": 0.012,
      "step": 560
    },
    {
      "epoch": 3.2241379310344827,
      "grad_norm": 0.12751145660877228,
      "learning_rate": 1.482307339660983e-05,
      "loss": 0.0056,
      "step": 561
    },
    {
      "epoch": 3.2298850574712645,
      "grad_norm": 0.2383992075920105,
      "learning_rate": 1.4738046062893695e-05,
      "loss": 0.0056,
      "step": 562
    },
    {
      "epoch": 3.235632183908046,
      "grad_norm": 0.19957298040390015,
      "learning_rate": 1.4653161248633051e-05,
      "loss": 0.0053,
      "step": 563
    },
    {
      "epoch": 3.2413793103448274,
      "grad_norm": 0.16099199652671814,
      "learning_rate": 1.4568420132720106e-05,
      "loss": 0.0068,
      "step": 564
    },
    {
      "epoch": 3.2471264367816093,
      "grad_norm": 0.10644625127315521,
      "learning_rate": 1.4483823892051345e-05,
      "loss": 0.004,
      "step": 565
    },
    {
      "epoch": 3.2528735632183907,
      "grad_norm": 0.08883719146251678,
      "learning_rate": 1.4399373701511246e-05,
      "loss": 0.0022,
      "step": 566
    },
    {
      "epoch": 3.2586206896551726,
      "grad_norm": 0.7062655091285706,
      "learning_rate": 1.4315070733955888e-05,
      "loss": 0.0293,
      "step": 567
    },
    {
      "epoch": 3.264367816091954,
      "grad_norm": 0.17404833436012268,
      "learning_rate": 1.4230916160196705e-05,
      "loss": 0.0067,
      "step": 568
    },
    {
      "epoch": 3.2701149425287355,
      "grad_norm": 0.6484012603759766,
      "learning_rate": 1.4146911148984227e-05,
      "loss": 0.0245,
      "step": 569
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 0.11498592793941498,
      "learning_rate": 1.4063056866991826e-05,
      "loss": 0.003,
      "step": 570
    },
    {
      "epoch": 3.281609195402299,
      "grad_norm": 0.43093693256378174,
      "learning_rate": 1.397935447879953e-05,
      "loss": 0.0136,
      "step": 571
    },
    {
      "epoch": 3.2873563218390807,
      "grad_norm": 0.352529913187027,
      "learning_rate": 1.389580514687785e-05,
      "loss": 0.0124,
      "step": 572
    },
    {
      "epoch": 3.293103448275862,
      "grad_norm": 0.2515253722667694,
      "learning_rate": 1.381241003157162e-05,
      "loss": 0.0089,
      "step": 573
    },
    {
      "epoch": 3.2988505747126435,
      "grad_norm": 0.5690346360206604,
      "learning_rate": 1.3729170291083892e-05,
      "loss": 0.0239,
      "step": 574
    },
    {
      "epoch": 3.3045977011494254,
      "grad_norm": 0.12850531935691833,
      "learning_rate": 1.3646087081459874e-05,
      "loss": 0.0049,
      "step": 575
    },
    {
      "epoch": 3.310344827586207,
      "grad_norm": 0.6564821004867554,
      "learning_rate": 1.3563161556570826e-05,
      "loss": 0.0284,
      "step": 576
    },
    {
      "epoch": 3.3160919540229887,
      "grad_norm": 0.9151215553283691,
      "learning_rate": 1.348039486809806e-05,
      "loss": 0.0574,
      "step": 577
    },
    {
      "epoch": 3.32183908045977,
      "grad_norm": 0.5868706703186035,
      "learning_rate": 1.3397788165516961e-05,
      "loss": 0.0287,
      "step": 578
    },
    {
      "epoch": 3.3275862068965516,
      "grad_norm": 0.319052129983902,
      "learning_rate": 1.3315342596080996e-05,
      "loss": 0.0094,
      "step": 579
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.7422282695770264,
      "learning_rate": 1.3233059304805797e-05,
      "loss": 0.0403,
      "step": 580
    },
    {
      "epoch": 3.339080459770115,
      "grad_norm": 0.1735621988773346,
      "learning_rate": 1.3150939434453254e-05,
      "loss": 0.0106,
      "step": 581
    },
    {
      "epoch": 3.344827586206897,
      "grad_norm": 0.4108514189720154,
      "learning_rate": 1.3068984125515644e-05,
      "loss": 0.0107,
      "step": 582
    },
    {
      "epoch": 3.3505747126436782,
      "grad_norm": 0.19281162321567535,
      "learning_rate": 1.2987194516199791e-05,
      "loss": 0.0061,
      "step": 583
    },
    {
      "epoch": 3.3563218390804597,
      "grad_norm": 0.39405524730682373,
      "learning_rate": 1.290557174241126e-05,
      "loss": 0.0095,
      "step": 584
    },
    {
      "epoch": 3.3620689655172415,
      "grad_norm": 0.11808256804943085,
      "learning_rate": 1.2824116937738579e-05,
      "loss": 0.0045,
      "step": 585
    },
    {
      "epoch": 3.367816091954023,
      "grad_norm": 0.06269471347332001,
      "learning_rate": 1.2742831233437499e-05,
      "loss": 0.0032,
      "step": 586
    },
    {
      "epoch": 3.3735632183908044,
      "grad_norm": 0.37854692339897156,
      "learning_rate": 1.2661715758415282e-05,
      "loss": 0.0111,
      "step": 587
    },
    {
      "epoch": 3.3793103448275863,
      "grad_norm": 0.5308587551116943,
      "learning_rate": 1.2580771639215027e-05,
      "loss": 0.0281,
      "step": 588
    },
    {
      "epoch": 3.3850574712643677,
      "grad_norm": 0.0745685026049614,
      "learning_rate": 1.2500000000000006e-05,
      "loss": 0.0036,
      "step": 589
    },
    {
      "epoch": 3.3908045977011496,
      "grad_norm": 0.4330127537250519,
      "learning_rate": 1.2419401962538074e-05,
      "loss": 0.0199,
      "step": 590
    },
    {
      "epoch": 3.396551724137931,
      "grad_norm": 0.5197252631187439,
      "learning_rate": 1.2338978646186084e-05,
      "loss": 0.0261,
      "step": 591
    },
    {
      "epoch": 3.4022988505747125,
      "grad_norm": 0.2974785268306732,
      "learning_rate": 1.2258731167874324e-05,
      "loss": 0.0121,
      "step": 592
    },
    {
      "epoch": 3.4080459770114944,
      "grad_norm": 0.2386757880449295,
      "learning_rate": 1.2178660642091037e-05,
      "loss": 0.0081,
      "step": 593
    },
    {
      "epoch": 3.413793103448276,
      "grad_norm": 0.1442856788635254,
      "learning_rate": 1.2098768180866895e-05,
      "loss": 0.0041,
      "step": 594
    },
    {
      "epoch": 3.4195402298850572,
      "grad_norm": 0.17429296672344208,
      "learning_rate": 1.2019054893759632e-05,
      "loss": 0.0048,
      "step": 595
    },
    {
      "epoch": 3.425287356321839,
      "grad_norm": 0.26152411103248596,
      "learning_rate": 1.1939521887838545e-05,
      "loss": 0.0055,
      "step": 596
    },
    {
      "epoch": 3.4310344827586206,
      "grad_norm": 0.3118191063404083,
      "learning_rate": 1.1860170267669174e-05,
      "loss": 0.0079,
      "step": 597
    },
    {
      "epoch": 3.4367816091954024,
      "grad_norm": 0.3787198066711426,
      "learning_rate": 1.1781001135297954e-05,
      "loss": 0.0121,
      "step": 598
    },
    {
      "epoch": 3.442528735632184,
      "grad_norm": 0.2687317430973053,
      "learning_rate": 1.170201559023689e-05,
      "loss": 0.0095,
      "step": 599
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.3536354899406433,
      "learning_rate": 1.1623214729448317e-05,
      "loss": 0.0101,
      "step": 600
    },
    {
      "epoch": 3.454022988505747,
      "grad_norm": 0.28555020689964294,
      "learning_rate": 1.1544599647329638e-05,
      "loss": 0.0101,
      "step": 601
    },
    {
      "epoch": 3.4597701149425286,
      "grad_norm": 0.1975233405828476,
      "learning_rate": 1.146617143569814e-05,
      "loss": 0.0042,
      "step": 602
    },
    {
      "epoch": 3.4655172413793105,
      "grad_norm": 0.1112566739320755,
      "learning_rate": 1.1387931183775822e-05,
      "loss": 0.0031,
      "step": 603
    },
    {
      "epoch": 3.471264367816092,
      "grad_norm": 0.42055779695510864,
      "learning_rate": 1.1309879978174279e-05,
      "loss": 0.0115,
      "step": 604
    },
    {
      "epoch": 3.4770114942528734,
      "grad_norm": 0.7308769822120667,
      "learning_rate": 1.1232018902879601e-05,
      "loss": 0.0377,
      "step": 605
    },
    {
      "epoch": 3.4827586206896552,
      "grad_norm": 0.6493749618530273,
      "learning_rate": 1.1154349039237322e-05,
      "loss": 0.0275,
      "step": 606
    },
    {
      "epoch": 3.4885057471264367,
      "grad_norm": 0.7799056768417358,
      "learning_rate": 1.1076871465937391e-05,
      "loss": 0.0366,
      "step": 607
    },
    {
      "epoch": 3.4942528735632186,
      "grad_norm": 0.949094831943512,
      "learning_rate": 1.0999587258999231e-05,
      "loss": 0.0283,
      "step": 608
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.8372132182121277,
      "learning_rate": 1.0922497491756734e-05,
      "loss": 0.0337,
      "step": 609
    },
    {
      "epoch": 3.5057471264367814,
      "grad_norm": 0.8124512434005737,
      "learning_rate": 1.0845603234843405e-05,
      "loss": 0.0414,
      "step": 610
    },
    {
      "epoch": 3.5114942528735633,
      "grad_norm": 0.18580187857151031,
      "learning_rate": 1.076890555617746e-05,
      "loss": 0.0036,
      "step": 611
    },
    {
      "epoch": 3.5172413793103448,
      "grad_norm": 0.2312076836824417,
      "learning_rate": 1.0692405520947028e-05,
      "loss": 0.0034,
      "step": 612
    },
    {
      "epoch": 3.5229885057471266,
      "grad_norm": 0.1630231887102127,
      "learning_rate": 1.061610419159532e-05,
      "loss": 0.0047,
      "step": 613
    },
    {
      "epoch": 3.528735632183908,
      "grad_norm": 0.5139751434326172,
      "learning_rate": 1.0540002627805897e-05,
      "loss": 0.0156,
      "step": 614
    },
    {
      "epoch": 3.5344827586206895,
      "grad_norm": 0.44940897822380066,
      "learning_rate": 1.0464101886487958e-05,
      "loss": 0.0112,
      "step": 615
    },
    {
      "epoch": 3.5402298850574714,
      "grad_norm": 0.7865760326385498,
      "learning_rate": 1.0388403021761637e-05,
      "loss": 0.0629,
      "step": 616
    },
    {
      "epoch": 3.545977011494253,
      "grad_norm": 0.35187146067619324,
      "learning_rate": 1.0312907084943384e-05,
      "loss": 0.0123,
      "step": 617
    },
    {
      "epoch": 3.5517241379310347,
      "grad_norm": 0.45865073800086975,
      "learning_rate": 1.0237615124531363e-05,
      "loss": 0.0124,
      "step": 618
    },
    {
      "epoch": 3.557471264367816,
      "grad_norm": 0.7946886420249939,
      "learning_rate": 1.0162528186190872e-05,
      "loss": 0.0302,
      "step": 619
    },
    {
      "epoch": 3.5632183908045976,
      "grad_norm": 0.9652389883995056,
      "learning_rate": 1.0087647312739848e-05,
      "loss": 0.0251,
      "step": 620
    },
    {
      "epoch": 3.5689655172413794,
      "grad_norm": 0.12691080570220947,
      "learning_rate": 1.0012973544134358e-05,
      "loss": 0.0032,
      "step": 621
    },
    {
      "epoch": 3.574712643678161,
      "grad_norm": 0.9598867893218994,
      "learning_rate": 9.93850791745418e-06,
      "loss": 0.0304,
      "step": 622
    },
    {
      "epoch": 3.5804597701149428,
      "grad_norm": 0.30421364307403564,
      "learning_rate": 9.864251466888363e-06,
      "loss": 0.012,
      "step": 623
    },
    {
      "epoch": 3.586206896551724,
      "grad_norm": 0.42579805850982666,
      "learning_rate": 9.79020522372093e-06,
      "loss": 0.0169,
      "step": 624
    },
    {
      "epoch": 3.5919540229885056,
      "grad_norm": 0.3640965223312378,
      "learning_rate": 9.716370216316484e-06,
      "loss": 0.0107,
      "step": 625
    },
    {
      "epoch": 3.5977011494252875,
      "grad_norm": 0.9667131304740906,
      "learning_rate": 9.64274747010596e-06,
      "loss": 0.0548,
      "step": 626
    },
    {
      "epoch": 3.603448275862069,
      "grad_norm": 0.4637688100337982,
      "learning_rate": 9.569338007572382e-06,
      "loss": 0.0097,
      "step": 627
    },
    {
      "epoch": 3.609195402298851,
      "grad_norm": 0.1941903829574585,
      "learning_rate": 9.496142848236661e-06,
      "loss": 0.0102,
      "step": 628
    },
    {
      "epoch": 3.6149425287356323,
      "grad_norm": 0.28992798924446106,
      "learning_rate": 9.423163008643438e-06,
      "loss": 0.0075,
      "step": 629
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 0.2549431622028351,
      "learning_rate": 9.35039950234696e-06,
      "loss": 0.0072,
      "step": 630
    },
    {
      "epoch": 3.626436781609195,
      "grad_norm": 0.18316881358623505,
      "learning_rate": 9.277853339897004e-06,
      "loss": 0.0067,
      "step": 631
    },
    {
      "epoch": 3.632183908045977,
      "grad_norm": 0.52370685338974,
      "learning_rate": 9.205525528824851e-06,
      "loss": 0.0193,
      "step": 632
    },
    {
      "epoch": 3.637931034482759,
      "grad_norm": 0.17601975798606873,
      "learning_rate": 9.133417073629289e-06,
      "loss": 0.0044,
      "step": 633
    },
    {
      "epoch": 3.6436781609195403,
      "grad_norm": 0.4095834791660309,
      "learning_rate": 9.061528975762647e-06,
      "loss": 0.014,
      "step": 634
    },
    {
      "epoch": 3.6494252873563218,
      "grad_norm": 0.5919696092605591,
      "learning_rate": 8.98986223361692e-06,
      "loss": 0.0154,
      "step": 635
    },
    {
      "epoch": 3.655172413793103,
      "grad_norm": 0.8939951658248901,
      "learning_rate": 8.918417842509867e-06,
      "loss": 0.0466,
      "step": 636
    },
    {
      "epoch": 3.660919540229885,
      "grad_norm": 1.2884526252746582,
      "learning_rate": 8.847196794671215e-06,
      "loss": 0.0589,
      "step": 637
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.22905567288398743,
      "learning_rate": 8.776200079228864e-06,
      "loss": 0.0122,
      "step": 638
    },
    {
      "epoch": 3.6724137931034484,
      "grad_norm": 0.23789843916893005,
      "learning_rate": 8.705428682195155e-06,
      "loss": 0.0075,
      "step": 639
    },
    {
      "epoch": 3.67816091954023,
      "grad_norm": 0.3543338179588318,
      "learning_rate": 8.634883586453178e-06,
      "loss": 0.0107,
      "step": 640
    },
    {
      "epoch": 3.6839080459770113,
      "grad_norm": 0.32315611839294434,
      "learning_rate": 8.564565771743104e-06,
      "loss": 0.01,
      "step": 641
    },
    {
      "epoch": 3.689655172413793,
      "grad_norm": 0.6112393736839294,
      "learning_rate": 8.494476214648626e-06,
      "loss": 0.019,
      "step": 642
    },
    {
      "epoch": 3.6954022988505746,
      "grad_norm": 0.21642202138900757,
      "learning_rate": 8.424615888583332e-06,
      "loss": 0.0063,
      "step": 643
    },
    {
      "epoch": 3.7011494252873565,
      "grad_norm": 0.6042543649673462,
      "learning_rate": 8.35498576377723e-06,
      "loss": 0.025,
      "step": 644
    },
    {
      "epoch": 3.706896551724138,
      "grad_norm": 0.0430721640586853,
      "learning_rate": 8.285586807263254e-06,
      "loss": 0.001,
      "step": 645
    },
    {
      "epoch": 3.7126436781609193,
      "grad_norm": 0.5128161311149597,
      "learning_rate": 8.216419982863852e-06,
      "loss": 0.0119,
      "step": 646
    },
    {
      "epoch": 3.718390804597701,
      "grad_norm": 0.4278545379638672,
      "learning_rate": 8.147486251177578e-06,
      "loss": 0.0129,
      "step": 647
    },
    {
      "epoch": 3.7241379310344827,
      "grad_norm": 0.14692294597625732,
      "learning_rate": 8.078786569565763e-06,
      "loss": 0.0058,
      "step": 648
    },
    {
      "epoch": 3.7298850574712645,
      "grad_norm": 0.15912172198295593,
      "learning_rate": 8.010321892139225e-06,
      "loss": 0.0041,
      "step": 649
    },
    {
      "epoch": 3.735632183908046,
      "grad_norm": 0.3227693438529968,
      "learning_rate": 7.942093169745005e-06,
      "loss": 0.0085,
      "step": 650
    },
    {
      "epoch": 3.7413793103448274,
      "grad_norm": 0.1926749348640442,
      "learning_rate": 7.874101349953167e-06,
      "loss": 0.0062,
      "step": 651
    },
    {
      "epoch": 3.7471264367816093,
      "grad_norm": 0.9716499447822571,
      "learning_rate": 7.80634737704363e-06,
      "loss": 0.0334,
      "step": 652
    },
    {
      "epoch": 3.7528735632183907,
      "grad_norm": 0.13350853323936462,
      "learning_rate": 7.738832191993093e-06,
      "loss": 0.0023,
      "step": 653
    },
    {
      "epoch": 3.7586206896551726,
      "grad_norm": 0.41325005888938904,
      "learning_rate": 7.671556732461905e-06,
      "loss": 0.0227,
      "step": 654
    },
    {
      "epoch": 3.764367816091954,
      "grad_norm": 0.6350752711296082,
      "learning_rate": 7.6045219327810806e-06,
      "loss": 0.0234,
      "step": 655
    },
    {
      "epoch": 3.7701149425287355,
      "grad_norm": 0.18943160772323608,
      "learning_rate": 7.537728723939322e-06,
      "loss": 0.0053,
      "step": 656
    },
    {
      "epoch": 3.7758620689655173,
      "grad_norm": 0.18776454031467438,
      "learning_rate": 7.471178033570081e-06,
      "loss": 0.0053,
      "step": 657
    },
    {
      "epoch": 3.781609195402299,
      "grad_norm": 0.49620726704597473,
      "learning_rate": 7.404870785938675e-06,
      "loss": 0.0124,
      "step": 658
    },
    {
      "epoch": 3.7873563218390807,
      "grad_norm": 0.3409288227558136,
      "learning_rate": 7.338807901929465e-06,
      "loss": 0.0099,
      "step": 659
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 1.067847490310669,
      "learning_rate": 7.272990299033045e-06,
      "loss": 0.069,
      "step": 660
    },
    {
      "epoch": 3.7988505747126435,
      "grad_norm": 0.5089767575263977,
      "learning_rate": 7.207418891333517e-06,
      "loss": 0.0147,
      "step": 661
    },
    {
      "epoch": 3.8045977011494254,
      "grad_norm": 0.2980840802192688,
      "learning_rate": 7.142094589495785e-06,
      "loss": 0.0071,
      "step": 662
    },
    {
      "epoch": 3.810344827586207,
      "grad_norm": 0.33698931336402893,
      "learning_rate": 7.077018300752916e-06,
      "loss": 0.0125,
      "step": 663
    },
    {
      "epoch": 3.8160919540229887,
      "grad_norm": 0.7091372609138489,
      "learning_rate": 7.012190928893533e-06,
      "loss": 0.0347,
      "step": 664
    },
    {
      "epoch": 3.82183908045977,
      "grad_norm": 0.16121423244476318,
      "learning_rate": 6.9476133742492706e-06,
      "loss": 0.0028,
      "step": 665
    },
    {
      "epoch": 3.8275862068965516,
      "grad_norm": 0.5211969614028931,
      "learning_rate": 6.883286533682265e-06,
      "loss": 0.0196,
      "step": 666
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 0.5120028257369995,
      "learning_rate": 6.819211300572697e-06,
      "loss": 0.0106,
      "step": 667
    },
    {
      "epoch": 3.839080459770115,
      "grad_norm": 0.5066085457801819,
      "learning_rate": 6.755388564806392e-06,
      "loss": 0.0133,
      "step": 668
    },
    {
      "epoch": 3.844827586206897,
      "grad_norm": 0.6176304221153259,
      "learning_rate": 6.691819212762454e-06,
      "loss": 0.0209,
      "step": 669
    },
    {
      "epoch": 3.8505747126436782,
      "grad_norm": 0.290393590927124,
      "learning_rate": 6.6285041273009605e-06,
      "loss": 0.0075,
      "step": 670
    },
    {
      "epoch": 3.8563218390804597,
      "grad_norm": 0.2683410048484802,
      "learning_rate": 6.565444187750699e-06,
      "loss": 0.0071,
      "step": 671
    },
    {
      "epoch": 3.862068965517241,
      "grad_norm": 0.19923251867294312,
      "learning_rate": 6.502640269896953e-06,
      "loss": 0.0048,
      "step": 672
    },
    {
      "epoch": 3.867816091954023,
      "grad_norm": 0.5943525433540344,
      "learning_rate": 6.440093245969342e-06,
      "loss": 0.0164,
      "step": 673
    },
    {
      "epoch": 3.873563218390805,
      "grad_norm": 0.2251305878162384,
      "learning_rate": 6.377803984629707e-06,
      "loss": 0.0073,
      "step": 674
    },
    {
      "epoch": 3.8793103448275863,
      "grad_norm": 0.42227402329444885,
      "learning_rate": 6.3157733509600355e-06,
      "loss": 0.0101,
      "step": 675
    },
    {
      "epoch": 3.8850574712643677,
      "grad_norm": 0.41691842675209045,
      "learning_rate": 6.254002206450485e-06,
      "loss": 0.0113,
      "step": 676
    },
    {
      "epoch": 3.890804597701149,
      "grad_norm": 0.13842405378818512,
      "learning_rate": 6.192491408987364e-06,
      "loss": 0.0053,
      "step": 677
    },
    {
      "epoch": 3.896551724137931,
      "grad_norm": 0.40808913111686707,
      "learning_rate": 6.1312418128412565e-06,
      "loss": 0.0128,
      "step": 678
    },
    {
      "epoch": 3.9022988505747125,
      "grad_norm": 0.5864184498786926,
      "learning_rate": 6.070254268655146e-06,
      "loss": 0.0185,
      "step": 679
    },
    {
      "epoch": 3.9080459770114944,
      "grad_norm": 0.3261057138442993,
      "learning_rate": 6.009529623432592e-06,
      "loss": 0.0058,
      "step": 680
    },
    {
      "epoch": 3.913793103448276,
      "grad_norm": 0.3742370009422302,
      "learning_rate": 5.949068720525991e-06,
      "loss": 0.0107,
      "step": 681
    },
    {
      "epoch": 3.9195402298850572,
      "grad_norm": 0.24580448865890503,
      "learning_rate": 5.888872399624832e-06,
      "loss": 0.0058,
      "step": 682
    },
    {
      "epoch": 3.925287356321839,
      "grad_norm": 0.11446325480937958,
      "learning_rate": 5.828941496744075e-06,
      "loss": 0.0044,
      "step": 683
    },
    {
      "epoch": 3.9310344827586206,
      "grad_norm": 0.25798872113227844,
      "learning_rate": 5.769276844212501e-06,
      "loss": 0.008,
      "step": 684
    },
    {
      "epoch": 3.9367816091954024,
      "grad_norm": 0.4683927893638611,
      "learning_rate": 5.70987927066117e-06,
      "loss": 0.0141,
      "step": 685
    },
    {
      "epoch": 3.942528735632184,
      "grad_norm": 0.2518787384033203,
      "learning_rate": 5.6507496010119125e-06,
      "loss": 0.0048,
      "step": 686
    },
    {
      "epoch": 3.9482758620689653,
      "grad_norm": 0.16006799042224884,
      "learning_rate": 5.591888656465874e-06,
      "loss": 0.0031,
      "step": 687
    },
    {
      "epoch": 3.954022988505747,
      "grad_norm": 0.3561536967754364,
      "learning_rate": 5.533297254492109e-06,
      "loss": 0.015,
      "step": 688
    },
    {
      "epoch": 3.9597701149425286,
      "grad_norm": 0.17820411920547485,
      "learning_rate": 5.474976208816224e-06,
      "loss": 0.0058,
      "step": 689
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 0.12138261646032333,
      "learning_rate": 5.416926329409083e-06,
      "loss": 0.002,
      "step": 690
    },
    {
      "epoch": 3.971264367816092,
      "grad_norm": 0.47656822204589844,
      "learning_rate": 5.359148422475549e-06,
      "loss": 0.0108,
      "step": 691
    },
    {
      "epoch": 3.9770114942528734,
      "grad_norm": 0.5174243450164795,
      "learning_rate": 5.3016432904432976e-06,
      "loss": 0.0137,
      "step": 692
    },
    {
      "epoch": 3.9827586206896552,
      "grad_norm": 0.34628021717071533,
      "learning_rate": 5.244411731951671e-06,
      "loss": 0.005,
      "step": 693
    },
    {
      "epoch": 3.9885057471264367,
      "grad_norm": 0.11902506649494171,
      "learning_rate": 5.187454541840575e-06,
      "loss": 0.0027,
      "step": 694
    },
    {
      "epoch": 3.9942528735632186,
      "grad_norm": 0.19335833191871643,
      "learning_rate": 5.130772511139456e-06,
      "loss": 0.0077,
      "step": 695
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.19414839148521423,
      "learning_rate": 5.074366427056309e-06,
      "loss": 0.0048,
      "step": 696
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.019114233553409576,
      "eval_runtime": 89.7683,
      "eval_samples_per_second": 0.98,
      "eval_steps_per_second": 0.49,
      "step": 696
    },
    {
      "epoch": 4.005747126436781,
      "grad_norm": 0.531277596950531,
      "learning_rate": 5.018237072966736e-06,
      "loss": 0.0131,
      "step": 697
    },
    {
      "epoch": 4.011494252873563,
      "grad_norm": 0.7099285125732422,
      "learning_rate": 4.96238522840308e-06,
      "loss": 0.0207,
      "step": 698
    },
    {
      "epoch": 4.017241379310345,
      "grad_norm": 0.32886868715286255,
      "learning_rate": 4.90681166904359e-06,
      "loss": 0.007,
      "step": 699
    },
    {
      "epoch": 4.022988505747127,
      "grad_norm": 0.06554614007472992,
      "learning_rate": 4.851517166701658e-06,
      "loss": 0.0017,
      "step": 700
    },
    {
      "epoch": 4.028735632183908,
      "grad_norm": 0.6249802112579346,
      "learning_rate": 4.79650248931508e-06,
      "loss": 0.014,
      "step": 701
    },
    {
      "epoch": 4.0344827586206895,
      "grad_norm": 0.15805579721927643,
      "learning_rate": 4.741768400935417e-06,
      "loss": 0.005,
      "step": 702
    },
    {
      "epoch": 4.040229885057471,
      "grad_norm": 1.2422034740447998,
      "learning_rate": 4.687315661717359e-06,
      "loss": 0.0324,
      "step": 703
    },
    {
      "epoch": 4.045977011494253,
      "grad_norm": 0.195443257689476,
      "learning_rate": 4.633145027908193e-06,
      "loss": 0.0037,
      "step": 704
    },
    {
      "epoch": 4.051724137931035,
      "grad_norm": 0.31721827387809753,
      "learning_rate": 4.579257251837271e-06,
      "loss": 0.0075,
      "step": 705
    },
    {
      "epoch": 4.057471264367816,
      "grad_norm": 0.8253741264343262,
      "learning_rate": 4.52565308190559e-06,
      "loss": 0.0242,
      "step": 706
    },
    {
      "epoch": 4.063218390804598,
      "grad_norm": 1.1281607151031494,
      "learning_rate": 4.472333262575376e-06,
      "loss": 0.0492,
      "step": 707
    },
    {
      "epoch": 4.068965517241379,
      "grad_norm": 0.21530681848526,
      "learning_rate": 4.419298534359759e-06,
      "loss": 0.0053,
      "step": 708
    },
    {
      "epoch": 4.074712643678161,
      "grad_norm": 0.46654197573661804,
      "learning_rate": 4.366549633812478e-06,
      "loss": 0.0124,
      "step": 709
    },
    {
      "epoch": 4.080459770114943,
      "grad_norm": 0.7372554540634155,
      "learning_rate": 4.314087293517671e-06,
      "loss": 0.0159,
      "step": 710
    },
    {
      "epoch": 4.086206896551724,
      "grad_norm": 0.18402142822742462,
      "learning_rate": 4.261912242079674e-06,
      "loss": 0.003,
      "step": 711
    },
    {
      "epoch": 4.091954022988506,
      "grad_norm": 0.23755648732185364,
      "learning_rate": 4.210025204112919e-06,
      "loss": 0.0046,
      "step": 712
    },
    {
      "epoch": 4.097701149425287,
      "grad_norm": 0.23145148158073425,
      "learning_rate": 4.1584269002318656e-06,
      "loss": 0.0043,
      "step": 713
    },
    {
      "epoch": 4.103448275862069,
      "grad_norm": 0.5442131757736206,
      "learning_rate": 4.107118047040995e-06,
      "loss": 0.013,
      "step": 714
    },
    {
      "epoch": 4.109195402298851,
      "grad_norm": 0.2056789994239807,
      "learning_rate": 4.0560993571248485e-06,
      "loss": 0.0043,
      "step": 715
    },
    {
      "epoch": 4.114942528735632,
      "grad_norm": 0.5491312146186829,
      "learning_rate": 4.005371539038158e-06,
      "loss": 0.017,
      "step": 716
    },
    {
      "epoch": 4.120689655172414,
      "grad_norm": 0.22841845452785492,
      "learning_rate": 3.954935297295975e-06,
      "loss": 0.0046,
      "step": 717
    },
    {
      "epoch": 4.126436781609195,
      "grad_norm": 0.11731048673391342,
      "learning_rate": 3.9047913323638944e-06,
      "loss": 0.0031,
      "step": 718
    },
    {
      "epoch": 4.1321839080459775,
      "grad_norm": 0.8769589066505432,
      "learning_rate": 3.854940340648333e-06,
      "loss": 0.0424,
      "step": 719
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 0.6563171744346619,
      "learning_rate": 3.8053830144868547e-06,
      "loss": 0.0126,
      "step": 720
    },
    {
      "epoch": 4.14367816091954,
      "grad_norm": 0.5545358061790466,
      "learning_rate": 3.756120042138561e-06,
      "loss": 0.0127,
      "step": 721
    },
    {
      "epoch": 4.149425287356322,
      "grad_norm": 0.8808127641677856,
      "learning_rate": 3.707152107774514e-06,
      "loss": 0.0173,
      "step": 722
    },
    {
      "epoch": 4.155172413793103,
      "grad_norm": 0.2891232669353485,
      "learning_rate": 3.6584798914682582e-06,
      "loss": 0.0045,
      "step": 723
    },
    {
      "epoch": 4.160919540229885,
      "grad_norm": 0.13254135847091675,
      "learning_rate": 3.6101040691863597e-06,
      "loss": 0.0019,
      "step": 724
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.36355769634246826,
      "learning_rate": 3.5620253127790186e-06,
      "loss": 0.0072,
      "step": 725
    },
    {
      "epoch": 4.172413793103448,
      "grad_norm": 0.7191213965415955,
      "learning_rate": 3.514244289970753e-06,
      "loss": 0.026,
      "step": 726
    },
    {
      "epoch": 4.17816091954023,
      "grad_norm": 0.2892846465110779,
      "learning_rate": 3.4667616643511035e-06,
      "loss": 0.0084,
      "step": 727
    },
    {
      "epoch": 4.183908045977011,
      "grad_norm": 0.19463995099067688,
      "learning_rate": 3.419578095365439e-06,
      "loss": 0.0039,
      "step": 728
    },
    {
      "epoch": 4.189655172413793,
      "grad_norm": 0.3646889626979828,
      "learning_rate": 3.3726942383057763e-06,
      "loss": 0.0055,
      "step": 729
    },
    {
      "epoch": 4.195402298850575,
      "grad_norm": 0.1316353678703308,
      "learning_rate": 3.3261107443017053e-06,
      "loss": 0.0034,
      "step": 730
    },
    {
      "epoch": 4.2011494252873565,
      "grad_norm": 0.31780755519866943,
      "learning_rate": 3.2798282603113155e-06,
      "loss": 0.0048,
      "step": 731
    },
    {
      "epoch": 4.206896551724138,
      "grad_norm": 0.6173431873321533,
      "learning_rate": 3.233847429112244e-06,
      "loss": 0.0139,
      "step": 732
    },
    {
      "epoch": 4.212643678160919,
      "grad_norm": 0.672657310962677,
      "learning_rate": 3.1881688892927197e-06,
      "loss": 0.0181,
      "step": 733
    },
    {
      "epoch": 4.218390804597701,
      "grad_norm": 0.10265087336301804,
      "learning_rate": 3.142793275242706e-06,
      "loss": 0.0026,
      "step": 734
    },
    {
      "epoch": 4.224137931034483,
      "grad_norm": 0.33861321210861206,
      "learning_rate": 3.0977212171451e-06,
      "loss": 0.0075,
      "step": 735
    },
    {
      "epoch": 4.2298850574712645,
      "grad_norm": 0.1403142362833023,
      "learning_rate": 3.052953340966963e-06,
      "loss": 0.0046,
      "step": 736
    },
    {
      "epoch": 4.235632183908046,
      "grad_norm": 0.23396305739879608,
      "learning_rate": 3.008490268450842e-06,
      "loss": 0.0133,
      "step": 737
    },
    {
      "epoch": 4.241379310344827,
      "grad_norm": 0.4312647879123688,
      "learning_rate": 2.9643326171061165e-06,
      "loss": 0.0103,
      "step": 738
    },
    {
      "epoch": 4.247126436781609,
      "grad_norm": 1.0264849662780762,
      "learning_rate": 2.9204810002004477e-06,
      "loss": 0.0196,
      "step": 739
    },
    {
      "epoch": 4.252873563218391,
      "grad_norm": 0.11785721778869629,
      "learning_rate": 2.876936026751234e-06,
      "loss": 0.0019,
      "step": 740
    },
    {
      "epoch": 4.258620689655173,
      "grad_norm": 0.044751863926649094,
      "learning_rate": 2.833698301517185e-06,
      "loss": 0.0009,
      "step": 741
    },
    {
      "epoch": 4.264367816091954,
      "grad_norm": 0.3081655502319336,
      "learning_rate": 2.790768424989887e-06,
      "loss": 0.0083,
      "step": 742
    },
    {
      "epoch": 4.2701149425287355,
      "grad_norm": 0.18860629200935364,
      "learning_rate": 2.7481469933854835e-06,
      "loss": 0.0038,
      "step": 743
    },
    {
      "epoch": 4.275862068965517,
      "grad_norm": 0.4535118639469147,
      "learning_rate": 2.7058345986363974e-06,
      "loss": 0.007,
      "step": 744
    },
    {
      "epoch": 4.281609195402299,
      "grad_norm": 0.23076511919498444,
      "learning_rate": 2.6638318283830982e-06,
      "loss": 0.0036,
      "step": 745
    },
    {
      "epoch": 4.287356321839081,
      "grad_norm": 0.21897326409816742,
      "learning_rate": 2.6221392659659533e-06,
      "loss": 0.0077,
      "step": 746
    },
    {
      "epoch": 4.293103448275862,
      "grad_norm": 0.7303075194358826,
      "learning_rate": 2.5807574904171155e-06,
      "loss": 0.0157,
      "step": 747
    },
    {
      "epoch": 4.2988505747126435,
      "grad_norm": 0.2398989200592041,
      "learning_rate": 2.5396870764524877e-06,
      "loss": 0.0043,
      "step": 748
    },
    {
      "epoch": 4.304597701149425,
      "grad_norm": 0.20004157721996307,
      "learning_rate": 2.498928594463734e-06,
      "loss": 0.0034,
      "step": 749
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.04551505669951439,
      "learning_rate": 2.4584826105103764e-06,
      "loss": 0.0007,
      "step": 750
    },
    {
      "epoch": 4.316091954022989,
      "grad_norm": 0.14262177050113678,
      "learning_rate": 2.4183496863119104e-06,
      "loss": 0.0026,
      "step": 751
    },
    {
      "epoch": 4.32183908045977,
      "grad_norm": 0.5039611458778381,
      "learning_rate": 2.3785303792400127e-06,
      "loss": 0.0096,
      "step": 752
    },
    {
      "epoch": 4.327586206896552,
      "grad_norm": 0.10013231635093689,
      "learning_rate": 2.3390252423108076e-06,
      "loss": 0.0017,
      "step": 753
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.21142823994159698,
      "learning_rate": 2.2998348241771744e-06,
      "loss": 0.0039,
      "step": 754
    },
    {
      "epoch": 4.3390804597701145,
      "grad_norm": 0.17411300539970398,
      "learning_rate": 2.2609596691211403e-06,
      "loss": 0.0031,
      "step": 755
    },
    {
      "epoch": 4.344827586206897,
      "grad_norm": 0.03581968694925308,
      "learning_rate": 2.222400317046308e-06,
      "loss": 0.0005,
      "step": 756
    },
    {
      "epoch": 4.350574712643678,
      "grad_norm": 0.25596919655799866,
      "learning_rate": 2.184157303470366e-06,
      "loss": 0.005,
      "step": 757
    },
    {
      "epoch": 4.35632183908046,
      "grad_norm": 0.5142099261283875,
      "learning_rate": 2.146231159517653e-06,
      "loss": 0.0095,
      "step": 758
    },
    {
      "epoch": 4.362068965517241,
      "grad_norm": 0.2117285281419754,
      "learning_rate": 2.108622411911773e-06,
      "loss": 0.0043,
      "step": 759
    },
    {
      "epoch": 4.3678160919540225,
      "grad_norm": 0.0319310799241066,
      "learning_rate": 2.071331582968289e-06,
      "loss": 0.0013,
      "step": 760
    },
    {
      "epoch": 4.373563218390805,
      "grad_norm": 0.2125760018825531,
      "learning_rate": 2.0343591905874647e-06,
      "loss": 0.0078,
      "step": 761
    },
    {
      "epoch": 4.379310344827586,
      "grad_norm": 0.688564658164978,
      "learning_rate": 1.997705748247067e-06,
      "loss": 0.013,
      "step": 762
    },
    {
      "epoch": 4.385057471264368,
      "grad_norm": 0.8079515695571899,
      "learning_rate": 1.961371764995243e-06,
      "loss": 0.0193,
      "step": 763
    },
    {
      "epoch": 4.390804597701149,
      "grad_norm": 0.16684837639331818,
      "learning_rate": 1.925357745443454e-06,
      "loss": 0.0019,
      "step": 764
    },
    {
      "epoch": 4.396551724137931,
      "grad_norm": 0.08789414167404175,
      "learning_rate": 1.8896641897594492e-06,
      "loss": 0.0023,
      "step": 765
    },
    {
      "epoch": 4.402298850574713,
      "grad_norm": 0.11285480856895447,
      "learning_rate": 1.8542915936603372e-06,
      "loss": 0.0038,
      "step": 766
    },
    {
      "epoch": 4.408045977011494,
      "grad_norm": 0.3598017692565918,
      "learning_rate": 1.819240448405693e-06,
      "loss": 0.0063,
      "step": 767
    },
    {
      "epoch": 4.413793103448276,
      "grad_norm": 0.1273258775472641,
      "learning_rate": 1.78451124079074e-06,
      "loss": 0.0027,
      "step": 768
    },
    {
      "epoch": 4.419540229885057,
      "grad_norm": 0.5051411986351013,
      "learning_rate": 1.7501044531395755e-06,
      "loss": 0.0085,
      "step": 769
    },
    {
      "epoch": 4.425287356321839,
      "grad_norm": 0.3581330478191376,
      "learning_rate": 1.7160205632985066e-06,
      "loss": 0.0057,
      "step": 770
    },
    {
      "epoch": 4.431034482758621,
      "grad_norm": 0.06422611325979233,
      "learning_rate": 1.6822600446293636e-06,
      "loss": 0.0013,
      "step": 771
    },
    {
      "epoch": 4.436781609195402,
      "grad_norm": 1.3732515573501587,
      "learning_rate": 1.6488233660029717e-06,
      "loss": 0.0774,
      "step": 772
    },
    {
      "epoch": 4.442528735632184,
      "grad_norm": 0.10808129608631134,
      "learning_rate": 1.61571099179261e-06,
      "loss": 0.0041,
      "step": 773
    },
    {
      "epoch": 4.448275862068965,
      "grad_norm": 0.12422670423984528,
      "learning_rate": 1.5829233818675766e-06,
      "loss": 0.0032,
      "step": 774
    },
    {
      "epoch": 4.454022988505747,
      "grad_norm": 0.3806934356689453,
      "learning_rate": 1.550460991586794e-06,
      "loss": 0.0077,
      "step": 775
    },
    {
      "epoch": 4.459770114942529,
      "grad_norm": 0.1508135199546814,
      "learning_rate": 1.5183242717924957e-06,
      "loss": 0.0022,
      "step": 776
    },
    {
      "epoch": 4.4655172413793105,
      "grad_norm": 0.8246666193008423,
      "learning_rate": 1.486513668803946e-06,
      "loss": 0.0213,
      "step": 777
    },
    {
      "epoch": 4.471264367816092,
      "grad_norm": 0.0316777341067791,
      "learning_rate": 1.4550296244112694e-06,
      "loss": 0.001,
      "step": 778
    },
    {
      "epoch": 4.477011494252873,
      "grad_norm": 0.04116300866007805,
      "learning_rate": 1.423872575869281e-06,
      "loss": 0.0012,
      "step": 779
    },
    {
      "epoch": 4.482758620689655,
      "grad_norm": 0.09510771930217743,
      "learning_rate": 1.3930429558914494e-06,
      "loss": 0.0021,
      "step": 780
    },
    {
      "epoch": 4.488505747126437,
      "grad_norm": 0.7049544453620911,
      "learning_rate": 1.362541192643854e-06,
      "loss": 0.0182,
      "step": 781
    },
    {
      "epoch": 4.494252873563219,
      "grad_norm": 0.5884791612625122,
      "learning_rate": 1.3323677097392628e-06,
      "loss": 0.0226,
      "step": 782
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.10535333305597305,
      "learning_rate": 1.3025229262312366e-06,
      "loss": 0.002,
      "step": 783
    },
    {
      "epoch": 4.505747126436781,
      "grad_norm": 1.4805539846420288,
      "learning_rate": 1.2730072566083162e-06,
      "loss": 0.0372,
      "step": 784
    },
    {
      "epoch": 4.511494252873563,
      "grad_norm": 0.23039095103740692,
      "learning_rate": 1.2438211107882651e-06,
      "loss": 0.0047,
      "step": 785
    },
    {
      "epoch": 4.517241379310345,
      "grad_norm": 0.291251540184021,
      "learning_rate": 1.214964894112361e-06,
      "loss": 0.0067,
      "step": 786
    },
    {
      "epoch": 4.522988505747127,
      "grad_norm": 0.761761486530304,
      "learning_rate": 1.1864390073397957e-06,
      "loss": 0.0197,
      "step": 787
    },
    {
      "epoch": 4.528735632183908,
      "grad_norm": 0.41465920209884644,
      "learning_rate": 1.1582438466420819e-06,
      "loss": 0.0077,
      "step": 788
    },
    {
      "epoch": 4.5344827586206895,
      "grad_norm": 0.7391074299812317,
      "learning_rate": 1.1303798035975643e-06,
      "loss": 0.012,
      "step": 789
    },
    {
      "epoch": 4.540229885057471,
      "grad_norm": 0.4420657753944397,
      "learning_rate": 1.102847265185983e-06,
      "loss": 0.0059,
      "step": 790
    },
    {
      "epoch": 4.545977011494253,
      "grad_norm": 0.03435550257563591,
      "learning_rate": 1.0756466137830906e-06,
      "loss": 0.0008,
      "step": 791
    },
    {
      "epoch": 4.551724137931035,
      "grad_norm": 0.17209501564502716,
      "learning_rate": 1.0487782271553504e-06,
      "loss": 0.0073,
      "step": 792
    },
    {
      "epoch": 4.557471264367816,
      "grad_norm": 0.5908340215682983,
      "learning_rate": 1.0222424784546852e-06,
      "loss": 0.0108,
      "step": 793
    },
    {
      "epoch": 4.563218390804598,
      "grad_norm": 1.0234559774398804,
      "learning_rate": 9.960397362132918e-07,
      "loss": 0.0354,
      "step": 794
    },
    {
      "epoch": 4.568965517241379,
      "grad_norm": 0.08511587232351303,
      "learning_rate": 9.701703643385295e-07,
      "loss": 0.0013,
      "step": 795
    },
    {
      "epoch": 4.574712643678161,
      "grad_norm": 0.08670888841152191,
      "learning_rate": 9.446347221078677e-07,
      "loss": 0.0017,
      "step": 796
    },
    {
      "epoch": 4.580459770114943,
      "grad_norm": 0.5870509147644043,
      "learning_rate": 9.194331641638798e-07,
      "loss": 0.0216,
      "step": 797
    },
    {
      "epoch": 4.586206896551724,
      "grad_norm": 0.35039034485816956,
      "learning_rate": 8.94566040509337e-07,
      "loss": 0.0049,
      "step": 798
    },
    {
      "epoch": 4.591954022988506,
      "grad_norm": 0.01670510694384575,
      "learning_rate": 8.700336965023481e-07,
      "loss": 0.0006,
      "step": 799
    },
    {
      "epoch": 4.597701149425287,
      "grad_norm": 0.09804967045783997,
      "learning_rate": 8.458364728515439e-07,
      "loss": 0.0036,
      "step": 800
    },
    {
      "epoch": 4.603448275862069,
      "grad_norm": 0.2345808446407318,
      "learning_rate": 8.219747056113586e-07,
      "loss": 0.004,
      "step": 801
    },
    {
      "epoch": 4.609195402298851,
      "grad_norm": 0.2781897187232971,
      "learning_rate": 7.984487261773616e-07,
      "loss": 0.0058,
      "step": 802
    },
    {
      "epoch": 4.614942528735632,
      "grad_norm": 0.6875694394111633,
      "learning_rate": 7.752588612816553e-07,
      "loss": 0.0207,
      "step": 803
    },
    {
      "epoch": 4.620689655172414,
      "grad_norm": 0.6794307827949524,
      "learning_rate": 7.524054329883346e-07,
      "loss": 0.0157,
      "step": 804
    },
    {
      "epoch": 4.626436781609195,
      "grad_norm": 0.15689830482006073,
      "learning_rate": 7.298887586890207e-07,
      "loss": 0.0022,
      "step": 805
    },
    {
      "epoch": 4.6321839080459775,
      "grad_norm": 0.3216616213321686,
      "learning_rate": 7.077091510984401e-07,
      "loss": 0.0056,
      "step": 806
    },
    {
      "epoch": 4.637931034482759,
      "grad_norm": 0.05962514877319336,
      "learning_rate": 6.858669182500971e-07,
      "loss": 0.0013,
      "step": 807
    },
    {
      "epoch": 4.64367816091954,
      "grad_norm": 0.7206663489341736,
      "learning_rate": 6.643623634919827e-07,
      "loss": 0.0115,
      "step": 808
    },
    {
      "epoch": 4.649425287356322,
      "grad_norm": 0.7792750597000122,
      "learning_rate": 6.431957854823673e-07,
      "loss": 0.0269,
      "step": 809
    },
    {
      "epoch": 4.655172413793103,
      "grad_norm": 0.14962631464004517,
      "learning_rate": 6.223674781856592e-07,
      "loss": 0.0024,
      "step": 810
    },
    {
      "epoch": 4.6609195402298855,
      "grad_norm": 0.13370269536972046,
      "learning_rate": 6.018777308683082e-07,
      "loss": 0.0028,
      "step": 811
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.5234991908073425,
      "learning_rate": 5.817268280948001e-07,
      "loss": 0.0118,
      "step": 812
    },
    {
      "epoch": 4.672413793103448,
      "grad_norm": 0.8951566815376282,
      "learning_rate": 5.619150497236992e-07,
      "loss": 0.019,
      "step": 813
    },
    {
      "epoch": 4.67816091954023,
      "grad_norm": 0.08965075016021729,
      "learning_rate": 5.424426709037589e-07,
      "loss": 0.0026,
      "step": 814
    },
    {
      "epoch": 4.683908045977011,
      "grad_norm": 0.23504014313220978,
      "learning_rate": 5.233099620701093e-07,
      "loss": 0.0051,
      "step": 815
    },
    {
      "epoch": 4.689655172413794,
      "grad_norm": 0.152247354388237,
      "learning_rate": 5.045171889404954e-07,
      "loss": 0.0029,
      "step": 816
    },
    {
      "epoch": 4.695402298850575,
      "grad_norm": 0.649135947227478,
      "learning_rate": 4.860646125115831e-07,
      "loss": 0.0146,
      "step": 817
    },
    {
      "epoch": 4.7011494252873565,
      "grad_norm": 0.13298442959785461,
      "learning_rate": 4.679524890553455e-07,
      "loss": 0.0049,
      "step": 818
    },
    {
      "epoch": 4.706896551724138,
      "grad_norm": 0.7047984600067139,
      "learning_rate": 4.501810701154907e-07,
      "loss": 0.01,
      "step": 819
    },
    {
      "epoch": 4.712643678160919,
      "grad_norm": 0.09789376705884933,
      "learning_rate": 4.327506025039785e-07,
      "loss": 0.0017,
      "step": 820
    },
    {
      "epoch": 4.718390804597701,
      "grad_norm": 0.49070480465888977,
      "learning_rate": 4.1566132829758687e-07,
      "loss": 0.0074,
      "step": 821
    },
    {
      "epoch": 4.724137931034483,
      "grad_norm": 0.3144485354423523,
      "learning_rate": 3.98913484834551e-07,
      "loss": 0.0067,
      "step": 822
    },
    {
      "epoch": 4.7298850574712645,
      "grad_norm": 0.15446321666240692,
      "learning_rate": 3.825073047112743e-07,
      "loss": 0.0037,
      "step": 823
    },
    {
      "epoch": 4.735632183908046,
      "grad_norm": 0.48223090171813965,
      "learning_rate": 3.6644301577908325e-07,
      "loss": 0.0118,
      "step": 824
    },
    {
      "epoch": 4.741379310344827,
      "grad_norm": 0.7701042890548706,
      "learning_rate": 3.507208411410778e-07,
      "loss": 0.0314,
      "step": 825
    },
    {
      "epoch": 4.747126436781609,
      "grad_norm": 0.3089064359664917,
      "learning_rate": 3.353409991490225e-07,
      "loss": 0.0057,
      "step": 826
    },
    {
      "epoch": 4.752873563218391,
      "grad_norm": 0.177692711353302,
      "learning_rate": 3.203037034003181e-07,
      "loss": 0.0061,
      "step": 827
    },
    {
      "epoch": 4.758620689655173,
      "grad_norm": 0.48429447412490845,
      "learning_rate": 3.0560916273504325e-07,
      "loss": 0.0127,
      "step": 828
    },
    {
      "epoch": 4.764367816091954,
      "grad_norm": 0.6269437074661255,
      "learning_rate": 2.9125758123303426e-07,
      "loss": 0.0145,
      "step": 829
    },
    {
      "epoch": 4.7701149425287355,
      "grad_norm": 0.1413641721010208,
      "learning_rate": 2.772491582110709e-07,
      "loss": 0.0048,
      "step": 830
    },
    {
      "epoch": 4.775862068965517,
      "grad_norm": 0.8216308355331421,
      "learning_rate": 2.635840882200924e-07,
      "loss": 0.0222,
      "step": 831
    },
    {
      "epoch": 4.781609195402299,
      "grad_norm": 0.5106213688850403,
      "learning_rate": 2.502625610425136e-07,
      "loss": 0.0096,
      "step": 832
    },
    {
      "epoch": 4.787356321839081,
      "grad_norm": 0.6486150622367859,
      "learning_rate": 2.3728476168956847e-07,
      "loss": 0.0213,
      "step": 833
    },
    {
      "epoch": 4.793103448275862,
      "grad_norm": 0.13084881007671356,
      "learning_rate": 2.246508703987543e-07,
      "loss": 0.0016,
      "step": 834
    },
    {
      "epoch": 4.7988505747126435,
      "grad_norm": 0.26375919580459595,
      "learning_rate": 2.1236106263132493e-07,
      "loss": 0.004,
      "step": 835
    },
    {
      "epoch": 4.804597701149425,
      "grad_norm": 0.19402343034744263,
      "learning_rate": 2.0041550906985397e-07,
      "loss": 0.0047,
      "step": 836
    },
    {
      "epoch": 4.810344827586206,
      "grad_norm": 1.3908365964889526,
      "learning_rate": 1.8881437561586722e-07,
      "loss": 0.0488,
      "step": 837
    },
    {
      "epoch": 4.816091954022989,
      "grad_norm": 1.1041854619979858,
      "learning_rate": 1.7755782338753356e-07,
      "loss": 0.0371,
      "step": 838
    },
    {
      "epoch": 4.82183908045977,
      "grad_norm": 0.013986962847411633,
      "learning_rate": 1.6664600871742486e-07,
      "loss": 0.0006,
      "step": 839
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 0.17543555796146393,
      "learning_rate": 1.5607908315035667e-07,
      "loss": 0.0021,
      "step": 840
    },
    {
      "epoch": 4.833333333333333,
      "grad_norm": 0.1769840568304062,
      "learning_rate": 1.4585719344127057e-07,
      "loss": 0.0068,
      "step": 841
    },
    {
      "epoch": 4.8390804597701145,
      "grad_norm": 0.962814211845398,
      "learning_rate": 1.3598048155320786e-07,
      "loss": 0.0243,
      "step": 842
    },
    {
      "epoch": 4.844827586206897,
      "grad_norm": 1.3954713344573975,
      "learning_rate": 1.264490846553279e-07,
      "loss": 0.0363,
      "step": 843
    },
    {
      "epoch": 4.850574712643678,
      "grad_norm": 0.31502386927604675,
      "learning_rate": 1.1726313512100407e-07,
      "loss": 0.0067,
      "step": 844
    },
    {
      "epoch": 4.85632183908046,
      "grad_norm": 0.02524898573756218,
      "learning_rate": 1.0842276052599742e-07,
      "loss": 0.0004,
      "step": 845
    },
    {
      "epoch": 4.862068965517241,
      "grad_norm": 0.5566137433052063,
      "learning_rate": 9.992808364666373e-08,
      "loss": 0.0071,
      "step": 846
    },
    {
      "epoch": 4.8678160919540225,
      "grad_norm": 0.15209335088729858,
      "learning_rate": 9.177922245827142e-08,
      "loss": 0.0048,
      "step": 847
    },
    {
      "epoch": 4.873563218390805,
      "grad_norm": 0.16527007520198822,
      "learning_rate": 8.397629013334741e-08,
      "loss": 0.006,
      "step": 848
    },
    {
      "epoch": 4.879310344827586,
      "grad_norm": 0.11406628042459488,
      "learning_rate": 7.651939504010885e-08,
      "loss": 0.0023,
      "step": 849
    },
    {
      "epoch": 4.885057471264368,
      "grad_norm": 1.3850390911102295,
      "learning_rate": 6.940864074095888e-08,
      "loss": 0.0538,
      "step": 850
    },
    {
      "epoch": 4.890804597701149,
      "grad_norm": 0.988129198551178,
      "learning_rate": 6.264412599105152e-08,
      "loss": 0.0307,
      "step": 851
    },
    {
      "epoch": 4.896551724137931,
      "grad_norm": 0.2144165337085724,
      "learning_rate": 5.622594473692067e-08,
      "loss": 0.0052,
      "step": 852
    },
    {
      "epoch": 4.902298850574713,
      "grad_norm": 0.7489905953407288,
      "learning_rate": 5.0154186115161647e-08,
      "loss": 0.0156,
      "step": 853
    },
    {
      "epoch": 4.908045977011494,
      "grad_norm": 1.1110841035842896,
      "learning_rate": 4.442893445121277e-08,
      "loss": 0.0305,
      "step": 854
    },
    {
      "epoch": 4.913793103448276,
      "grad_norm": 0.479441374540329,
      "learning_rate": 3.90502692581729e-08,
      "loss": 0.0098,
      "step": 855
    },
    {
      "epoch": 4.919540229885057,
      "grad_norm": 0.0864911675453186,
      "learning_rate": 3.401826523569407e-08,
      "loss": 0.0035,
      "step": 856
    },
    {
      "epoch": 4.925287356321839,
      "grad_norm": 0.309662789106369,
      "learning_rate": 2.9332992268960026e-08,
      "loss": 0.0035,
      "step": 857
    },
    {
      "epoch": 4.931034482758621,
      "grad_norm": 0.2356254607439041,
      "learning_rate": 2.4994515427695374e-08,
      "loss": 0.0042,
      "step": 858
    },
    {
      "epoch": 4.936781609195402,
      "grad_norm": 0.2653413712978363,
      "learning_rate": 2.1002894965274633e-08,
      "loss": 0.0047,
      "step": 859
    },
    {
      "epoch": 4.942528735632184,
      "grad_norm": 0.4649604260921478,
      "learning_rate": 1.7358186317883996e-08,
      "loss": 0.0098,
      "step": 860
    },
    {
      "epoch": 4.948275862068965,
      "grad_norm": 0.7749701738357544,
      "learning_rate": 1.4060440103746964e-08,
      "loss": 0.0146,
      "step": 861
    },
    {
      "epoch": 4.954022988505747,
      "grad_norm": 0.4662262499332428,
      "learning_rate": 1.1109702122427678e-08,
      "loss": 0.0087,
      "step": 862
    },
    {
      "epoch": 4.959770114942529,
      "grad_norm": 0.08713415265083313,
      "learning_rate": 8.506013354186992e-09,
      "loss": 0.0013,
      "step": 863
    },
    {
      "epoch": 4.9655172413793105,
      "grad_norm": 0.16859111189842224,
      "learning_rate": 6.249409959421803e-09,
      "loss": 0.0033,
      "step": 864
    },
    {
      "epoch": 4.971264367816092,
      "grad_norm": 0.1029297411441803,
      "learning_rate": 4.339923278151581e-09,
      "loss": 0.0021,
      "step": 865
    },
    {
      "epoch": 4.977011494252873,
      "grad_norm": 0.5187584757804871,
      "learning_rate": 2.7775798296020282e-09,
      "loss": 0.0106,
      "step": 866
    },
    {
      "epoch": 4.982758620689655,
      "grad_norm": 0.2511821389198303,
      "learning_rate": 1.5624013118137326e-09,
      "loss": 0.0046,
      "step": 867
    },
    {
      "epoch": 4.988505747126437,
      "grad_norm": 0.24033616483211517,
      "learning_rate": 6.944046013562799e-10,
      "loss": 0.0048,
      "step": 868
    },
    {
      "epoch": 4.994252873563219,
      "grad_norm": 0.46672120690345764,
      "learning_rate": 1.736017530895584e-10,
      "loss": 0.0135,
      "step": 869
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.144133523106575,
      "learning_rate": 0.0,
      "loss": 0.0027,
      "step": 870
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.020257139578461647,
      "eval_runtime": 91.5539,
      "eval_samples_per_second": 0.961,
      "eval_steps_per_second": 0.481,
      "step": 870
    },
    {
      "epoch": 5.0,
      "step": 870,
      "total_flos": 1.3025711291891712e+17,
      "train_loss": 0.09640089619935532,
      "train_runtime": 5866.2978,
      "train_samples_per_second": 0.296,
      "train_steps_per_second": 0.148
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 870,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3025711291891712e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
